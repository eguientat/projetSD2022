2022-10-21 10:50:39,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = MI104-08/172.31.18.37
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.10.2
STARTUP_MSG:   classpath = /travail/te131323/hadoop/hadoop-2.10.2/etc/hadoop:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-json-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-digester-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hadoop-annotations-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-net-3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/junit-4.13.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/zookeeper-3.4.14.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/httpcore-4.4.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/gson-2.2.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsp-api-2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/httpclient-4.5.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/activation-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/stax2-api-4.2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/spotbugs-annotations-3.1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hadoop-auth-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/json-smart-1.3.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsch-0.1.55.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jettison-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-nfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-common-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xercesImpl-2.12.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/netty-all-4.1.50.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xml-apis-1.4.01.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-databind-2.9.10.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-client-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/javax.inject-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/woodstox-core-5.3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/nimbus-jose-jwt-7.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/zookeeper-3.4.14.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-beanutils-1.9.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/audience-annotations-0.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/httpcore-4.4.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-framework-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/fst-2.50.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-client-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/httpclient-4.5.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/activation-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/stax2-api-4.2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-recipes-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/spotbugs-annotations-3.1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/json-smart-1.3.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsch-0.1.55.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guice-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jettison-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-router-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-registry-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-api-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/junit-4.13.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.10.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r 965fd380006fa78b2315668fbc7eb432e1d8200f; compiled by 'ubuntu' on 2022-05-24T22:35Z
STARTUP_MSG:   java = 1.8.0_333
************************************************************/
2022-10-21 10:50:39,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2022-10-21 10:50:39,655 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/travail/te131323/datadir/
2022-10-21 10:50:39,694 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2022-10-21 10:50:39,729 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2022-10-21 10:50:39,729 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2022-10-21 10:50:39,903 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-10-21 10:50:39,909 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2022-10-21 10:50:39,910 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is MI104-08
2022-10-21 10:50:39,910 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-10-21 10:50:39,910 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2022-10-21 10:50:39,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2022-10-21 10:50:39,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Shutdown complete.
2022-10-21 10:50:39,923 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.net.BindException: Problem binding to [0.0.0.0:50010] java.net.BindException: Adresse déjà utilisée; For more details see:  http://wiki.apache.org/hadoop/BindException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:827)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:738)
	at org.apache.hadoop.ipc.Server.bind(Server.java:623)
	at org.apache.hadoop.ipc.Server.bind(Server.java:595)
	at org.apache.hadoop.hdfs.net.TcpPeerServer.<init>(TcpPeerServer.java:52)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1120)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1374)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:499)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2712)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2615)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2662)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2806)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2830)
Caused by: java.net.BindException: Adresse déjà utilisée
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:438)
	at sun.nio.ch.Net.bind(Net.java:430)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:225)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.apache.hadoop.ipc.Server.bind(Server.java:606)
	... 10 more
2022-10-21 10:50:39,924 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1: java.net.BindException: Problem binding to [0.0.0.0:50010] java.net.BindException: Adresse déjà utilisée; For more details see:  http://wiki.apache.org/hadoop/BindException
2022-10-21 10:50:39,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at MI104-08/172.31.18.37
************************************************************/
2022-11-23 10:19:37,534 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = MI104-08/172.31.18.37
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.10.2
STARTUP_MSG:   classpath = /travail/te131323/hadoop/hadoop-2.10.2/etc/hadoop:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-json-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-digester-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hadoop-annotations-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-net-3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/junit-4.13.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/zookeeper-3.4.14.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/httpcore-4.4.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/gson-2.2.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsp-api-2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/httpclient-4.5.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/activation-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/stax2-api-4.2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/spotbugs-annotations-3.1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hadoop-auth-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/json-smart-1.3.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsch-0.1.55.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jettison-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-nfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-common-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xercesImpl-2.12.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/netty-all-4.1.50.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xml-apis-1.4.01.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-databind-2.9.10.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-client-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/javax.inject-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/woodstox-core-5.3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/nimbus-jose-jwt-7.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/zookeeper-3.4.14.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-beanutils-1.9.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/audience-annotations-0.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/httpcore-4.4.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-framework-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/fst-2.50.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-client-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/httpclient-4.5.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/activation-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/stax2-api-4.2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-recipes-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/spotbugs-annotations-3.1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/json-smart-1.3.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsch-0.1.55.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guice-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jettison-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-router-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-registry-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-api-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/junit-4.13.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.10.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r 965fd380006fa78b2315668fbc7eb432e1d8200f; compiled by 'ubuntu' on 2022-05-24T22:35Z
STARTUP_MSG:   java = 1.8.0_333
************************************************************/
2022-11-23 10:19:37,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2022-11-23 10:19:37,757 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/travail/te131323/datadir/
2022-11-23 10:19:37,784 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2022-11-23 10:19:37,819 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2022-11-23 10:19:37,819 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2022-11-23 10:19:37,977 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-11-23 10:19:37,985 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2022-11-23 10:19:37,987 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is MI104-08
2022-11-23 10:19:37,987 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-11-23 10:19:37,987 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2022-11-23 10:19:37,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2022-11-23 10:19:37,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2022-11-23 10:19:38,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2022-11-23 10:19:38,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2022-11-23 10:19:38,046 INFO org.mortbay.log: Logging to org.slf4j.impl.Reload4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2022-11-23 10:19:38,050 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-11-23 10:19:38,052 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2022-11-23 10:19:38,055 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2022-11-23 10:19:38,056 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2022-11-23 10:19:38,056 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-11-23 10:19:38,056 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-11-23 10:19:38,086 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 44871
2022-11-23 10:19:38,087 INFO org.mortbay.log: jetty-6.1.26
2022-11-23 10:19:38,174 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:44871
2022-11-23 10:19:38,253 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2022-11-23 10:19:38,256 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2022-11-23 10:19:38,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = te131323
2022-11-23 10:19:38,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2022-11-23 10:19:38,272 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2022-11-23 10:19:38,278 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2022-11-23 10:19:38,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2022-11-23 10:19:38,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2022-11-23 10:19:38,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2022-11-23 10:19:38,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2022-11-23 10:19:38,334 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2022-11-23 10:19:38,334 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2022-11-23 10:19:38,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2022-11-23 10:19:38,443 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2022-11-23 10:19:38,445 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /travail/te131323/datadir/in_use.lock acquired by nodename 152941@MI104-08
2022-11-23 10:19:38,446 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /travail/te131323/datadir is not formatted for namespace 1416346374. Formatting...
2022-11-23 10:19:38,446 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-96111c62-5ff4-403b-b84a-0495c50b7c55 for directory /travail/te131323/datadir
2022-11-23 10:19:38,465 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1039181720-172.31.18.37-1669195160655
2022-11-23 10:19:38,465 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /travail/te131323/datadir/current/BP-1039181720-172.31.18.37-1669195160655
2022-11-23 10:19:38,465 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /travail/te131323/datadir/current/BP-1039181720-172.31.18.37-1669195160655 is not formatted for BP-1039181720-172.31.18.37-1669195160655. Formatting ...
2022-11-23 10:19:38,465 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1039181720-172.31.18.37-1669195160655 directory /travail/te131323/datadir/current/BP-1039181720-172.31.18.37-1669195160655/current
2022-11-23 10:19:38,467 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1416346374;bpid=BP-1039181720-172.31.18.37-1669195160655;lv=-57;nsInfo=lv=-63;cid=CID-a7af8c60-375a-4436-bea8-169fc18087fe;nsid=1416346374;c=1669195160655;bpid=BP-1039181720-172.31.18.37-1669195160655;dnuuid=null
2022-11-23 10:19:38,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID f2462099-cd02-473b-8fc9-c6a6551815ce
2022-11-23 10:19:38,478 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.lock-reporting-threshold-ms(300) assuming MILLISECONDS
2022-11-23 10:19:38,494 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-96111c62-5ff4-403b-b84a-0495c50b7c55
2022-11-23 10:19:38,494 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /travail/te131323/datadir/current, StorageType: DISK
2022-11-23 10:19:38,497 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2022-11-23 10:19:38,501 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /travail/te131323/datadir/current
2022-11-23 10:19:38,505 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /travail/te131323/datadir/current
2022-11-23 10:19:38,506 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1039181720-172.31.18.37-1669195160655
2022-11-23 10:19:38,507 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1039181720-172.31.18.37-1669195160655 on volume /travail/te131323/datadir/current...
2022-11-23 10:19:38,524 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1039181720-172.31.18.37-1669195160655 on /travail/te131323/datadir/current: 17ms
2022-11-23 10:19:38,524 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1039181720-172.31.18.37-1669195160655: 18ms
2022-11-23 10:19:38,526 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1039181720-172.31.18.37-1669195160655 on volume /travail/te131323/datadir/current...
2022-11-23 10:19:38,526 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /travail/te131323/datadir/current/BP-1039181720-172.31.18.37-1669195160655/current/replicas doesn't exist 
2022-11-23 10:19:38,526 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1039181720-172.31.18.37-1669195160655 on volume /travail/te131323/datadir/current: 0ms
2022-11-23 10:19:38,527 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-1039181720-172.31.18.37-1669195160655: 2ms
2022-11-23 10:19:38,528 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1039181720-172.31.18.37-1669195160655 on volume /travail/te131323/datadir
2022-11-23 10:19:38,528 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/travail/te131323/datadir, DS-96111c62-5ff4-403b-b84a-0495c50b7c55): finished scanning block pool BP-1039181720-172.31.18.37-1669195160655
2022-11-23 10:19:38,532 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 23/11/22 11:20 with interval of 21600000ms
2022-11-23 10:19:38,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1039181720-172.31.18.37-1669195160655 (Datanode Uuid f2462099-cd02-473b-8fc9-c6a6551815ce) service to localhost/127.0.0.1:9000 beginning handshake with NN
2022-11-23 10:19:38,541 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/travail/te131323/datadir, DS-96111c62-5ff4-403b-b84a-0495c50b7c55): no suitable block pools found to scan.  Waiting 1814399986 ms.
2022-11-23 10:19:38,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1039181720-172.31.18.37-1669195160655 (Datanode Uuid f2462099-cd02-473b-8fc9-c6a6551815ce) service to localhost/127.0.0.1:9000 successfully registered with NN
2022-11-23 10:19:38,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2022-11-23 10:19:38,630 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x70446da9214d0267,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 24 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2022-11-23 10:19:38,630 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1039181720-172.31.18.37-1669195160655
2022-11-23 10:24:31,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1039181720-172.31.18.37-1669195160655:blk_1073741825_1001 src: /127.0.0.1:41662 dest: /127.0.0.1:50010
2022-11-23 10:24:31,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:41662, dest: /127.0.0.1:50010, bytes: 40, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1679743770_1, offset: 0, srvID: f2462099-cd02-473b-8fc9-c6a6551815ce, blockid: BP-1039181720-172.31.18.37-1669195160655:blk_1073741825_1001, duration(ns): 7065234
2022-11-23 10:24:31,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1039181720-172.31.18.37-1669195160655:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2022-11-23 10:54:47,289 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1039181720-172.31.18.37-1669195160655:blk_1073741826_1002 src: /127.0.0.1:40640 dest: /127.0.0.1:50010
2022-11-23 10:54:47,293 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:40640, dest: /127.0.0.1:50010, bytes: 16, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1284415543_1, offset: 0, srvID: f2462099-cd02-473b-8fc9-c6a6551815ce, blockid: BP-1039181720-172.31.18.37-1669195160655:blk_1073741826_1002, duration(ns): 3251380
2022-11-23 10:54:47,293 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1039181720-172.31.18.37-1669195160655:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2022-11-23 11:07:13,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1039181720-172.31.18.37-1669195160655:blk_1073741827_1003 src: /127.0.0.1:52212 dest: /127.0.0.1:50010
2022-11-23 11:07:13,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52212, dest: /127.0.0.1:50010, bytes: 16, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-281887311_1, offset: 0, srvID: f2462099-cd02-473b-8fc9-c6a6551815ce, blockid: BP-1039181720-172.31.18.37-1669195160655:blk_1073741827_1003, duration(ns): 3011873
2022-11-23 11:07:13,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1039181720-172.31.18.37-1669195160655:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2022-11-23 11:17:18,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1039181720-172.31.18.37-1669195160655:blk_1073741828_1004 src: /127.0.0.1:39442 dest: /127.0.0.1:50010
2022-11-23 11:17:18,258 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:39442, dest: /127.0.0.1:50010, bytes: 16, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1736008686_1, offset: 0, srvID: f2462099-cd02-473b-8fc9-c6a6551815ce, blockid: BP-1039181720-172.31.18.37-1669195160655:blk_1073741828_1004, duration(ns): 2990800
2022-11-23 11:17:18,258 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1039181720-172.31.18.37-1669195160655:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2022-11-23 11:17:48,801 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1039181720-172.31.18.37-1669195160655:blk_1073741829_1005 src: /127.0.0.1:56804 dest: /127.0.0.1:50010
2022-11-23 11:17:48,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56804, dest: /127.0.0.1:50010, bytes: 16, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_320687571_1, offset: 0, srvID: f2462099-cd02-473b-8fc9-c6a6551815ce, blockid: BP-1039181720-172.31.18.37-1669195160655:blk_1073741829_1005, duration(ns): 2895863
2022-11-23 11:17:48,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1039181720-172.31.18.37-1669195160655:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2022-11-23 11:20:20,542 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1039181720-172.31.18.37-1669195160655 Total blocks: 5, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2022-11-23 11:23:43,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1039181720-172.31.18.37-1669195160655:blk_1073741830_1006 src: /127.0.0.1:33286 dest: /127.0.0.1:50010
2022-11-23 11:23:43,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:33286, dest: /127.0.0.1:50010, bytes: 16, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1684678646_1, offset: 0, srvID: f2462099-cd02-473b-8fc9-c6a6551815ce, blockid: BP-1039181720-172.31.18.37-1669195160655:blk_1073741830_1006, duration(ns): 3099495
2022-11-23 11:23:43,596 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1039181720-172.31.18.37-1669195160655:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2022-11-23 11:32:44,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1039181720-172.31.18.37-1669195160655:blk_1073741831_1007 src: /127.0.0.1:43736 dest: /127.0.0.1:50010
2022-11-23 11:32:44,359 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:43736, dest: /127.0.0.1:50010, bytes: 72, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1087656559_1, offset: 0, srvID: f2462099-cd02-473b-8fc9-c6a6551815ce, blockid: BP-1039181720-172.31.18.37-1669195160655:blk_1073741831_1007, duration(ns): 4169962
2022-11-23 11:32:44,359 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1039181720-172.31.18.37-1669195160655:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2022-11-23 11:35:16,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1039181720-172.31.18.37-1669195160655:blk_1073741832_1008 src: /127.0.0.1:32842 dest: /127.0.0.1:50010
2022-11-23 11:35:16,665 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:32842, dest: /127.0.0.1:50010, bytes: 72, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-890790476_1, offset: 0, srvID: f2462099-cd02-473b-8fc9-c6a6551815ce, blockid: BP-1039181720-172.31.18.37-1669195160655:blk_1073741832_1008, duration(ns): 4565065
2022-11-23 11:35:16,665 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1039181720-172.31.18.37-1669195160655:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2022-11-23 11:37:16,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1039181720-172.31.18.37-1669195160655:blk_1073741833_1009 src: /127.0.0.1:57378 dest: /127.0.0.1:50010
2022-11-23 11:37:16,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:57378, dest: /127.0.0.1:50010, bytes: 40, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_456793906_1, offset: 0, srvID: f2462099-cd02-473b-8fc9-c6a6551815ce, blockid: BP-1039181720-172.31.18.37-1669195160655:blk_1073741833_1009, duration(ns): 4490855
2022-11-23 11:37:16,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1039181720-172.31.18.37-1669195160655:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2022-11-23 11:37:58,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1039181720-172.31.18.37-1669195160655:blk_1073741834_1010 src: /127.0.0.1:44354 dest: /127.0.0.1:50010
2022-11-23 11:37:58,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44354, dest: /127.0.0.1:50010, bytes: 16, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_327510772_1, offset: 0, srvID: f2462099-cd02-473b-8fc9-c6a6551815ce, blockid: BP-1039181720-172.31.18.37-1669195160655:blk_1073741834_1010, duration(ns): 2738352
2022-11-23 11:37:58,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1039181720-172.31.18.37-1669195160655:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2022-11-23 11:39:44,852 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1039181720-172.31.18.37-1669195160655:blk_1073741835_1011 src: /127.0.0.1:47496 dest: /127.0.0.1:50010
2022-11-23 11:39:44,855 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:47496, dest: /127.0.0.1:50010, bytes: 16, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2093952390_1, offset: 0, srvID: f2462099-cd02-473b-8fc9-c6a6551815ce, blockid: BP-1039181720-172.31.18.37-1669195160655:blk_1073741835_1011, duration(ns): 2848431
2022-11-23 11:39:44,855 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1039181720-172.31.18.37-1669195160655:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2022-11-23 11:41:32,611 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1039181720-172.31.18.37-1669195160655:blk_1073741836_1012 src: /127.0.0.1:49332 dest: /127.0.0.1:50010
2022-11-23 11:41:32,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49332, dest: /127.0.0.1:50010, bytes: 16, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1368534458_1, offset: 0, srvID: f2462099-cd02-473b-8fc9-c6a6551815ce, blockid: BP-1039181720-172.31.18.37-1669195160655:blk_1073741836_1012, duration(ns): 2833373
2022-11-23 11:41:32,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1039181720-172.31.18.37-1669195160655:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2022-11-23 11:46:29,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1039181720-172.31.18.37-1669195160655:blk_1073741837_1013 src: /127.0.0.1:34606 dest: /127.0.0.1:50010
2022-11-23 11:46:29,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:34606, dest: /127.0.0.1:50010, bytes: 16, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2065930273_1, offset: 0, srvID: f2462099-cd02-473b-8fc9-c6a6551815ce, blockid: BP-1039181720-172.31.18.37-1669195160655:blk_1073741837_1013, duration(ns): 2937872
2022-11-23 11:46:29,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1039181720-172.31.18.37-1669195160655:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2022-11-23 11:52:02,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1039181720-172.31.18.37-1669195160655:blk_1073741838_1014 src: /127.0.0.1:39544 dest: /127.0.0.1:50010
2022-11-23 11:52:02,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:39544, dest: /127.0.0.1:50010, bytes: 16, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_854067267_1, offset: 0, srvID: f2462099-cd02-473b-8fc9-c6a6551815ce, blockid: BP-1039181720-172.31.18.37-1669195160655:blk_1073741838_1014, duration(ns): 3050811
2022-11-23 11:52:02,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1039181720-172.31.18.37-1669195160655:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2022-11-23 11:58:58,230 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1039181720-172.31.18.37-1669195160655:blk_1073741839_1015 src: /127.0.0.1:45880 dest: /127.0.0.1:50010
2022-11-23 11:58:58,234 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:45880, dest: /127.0.0.1:50010, bytes: 16, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1455732706_1, offset: 0, srvID: f2462099-cd02-473b-8fc9-c6a6551815ce, blockid: BP-1039181720-172.31.18.37-1669195160655:blk_1073741839_1015, duration(ns): 2882408
2022-11-23 11:58:58,234 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1039181720-172.31.18.37-1669195160655:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2022-11-23 12:02:44,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1039181720-172.31.18.37-1669195160655:blk_1073741840_1016 src: /127.0.0.1:45592 dest: /127.0.0.1:50010
2022-11-23 12:02:44,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:45592, dest: /127.0.0.1:50010, bytes: 16, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-295922082_1, offset: 0, srvID: f2462099-cd02-473b-8fc9-c6a6551815ce, blockid: BP-1039181720-172.31.18.37-1669195160655:blk_1073741840_1016, duration(ns): 2933735
2022-11-23 12:02:44,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1039181720-172.31.18.37-1669195160655:blk_1073741840_1016, type=LAST_IN_PIPELINE terminating
2022-11-23 12:07:21,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1039181720-172.31.18.37-1669195160655:blk_1073741841_1017 src: /127.0.0.1:53336 dest: /127.0.0.1:50010
2022-11-23 12:07:21,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:53336, dest: /127.0.0.1:50010, bytes: 16, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2107688868_1, offset: 0, srvID: f2462099-cd02-473b-8fc9-c6a6551815ce, blockid: BP-1039181720-172.31.18.37-1669195160655:blk_1073741841_1017, duration(ns): 3071240
2022-11-23 12:07:21,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1039181720-172.31.18.37-1669195160655:blk_1073741841_1017, type=LAST_IN_PIPELINE terminating
2022-11-23 14:52:27,585 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x70446da9214d0268,  containing 1 storage report(s), of which we sent 1. The reports had 17 total blocks and used 1 RPC(s). This took 1 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2022-11-23 14:52:27,586 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1039181720-172.31.18.37-1669195160655
2022-11-23 17:20:20,538 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1039181720-172.31.18.37-1669195160655 Total blocks: 17, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2022-11-23 20:52:26,943 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x70446da9214d0269,  containing 1 storage report(s), of which we sent 1. The reports had 17 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2022-11-23 20:52:26,943 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1039181720-172.31.18.37-1669195160655
2022-11-23 23:20:20,537 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1039181720-172.31.18.37-1669195160655 Total blocks: 17, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2022-11-24 02:52:26,516 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x70446da9214d026a,  containing 1 storage report(s), of which we sent 1. The reports had 17 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2022-11-24 02:52:26,516 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1039181720-172.31.18.37-1669195160655
2022-11-24 05:20:20,537 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1039181720-172.31.18.37-1669195160655 Total blocks: 17, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2022-11-24 08:52:26,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x70446da9214d026b,  containing 1 storage report(s), of which we sent 1. The reports had 17 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2022-11-24 08:52:26,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1039181720-172.31.18.37-1669195160655
2022-11-24 11:20:20,533 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1039181720-172.31.18.37-1669195160655 Total blocks: 17, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2022-11-24 15:39:45,429 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6211ms
No GCs detected
2022-11-24 15:42:34,628 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3316ms
No GCs detected
2022-11-24 16:30:01,613 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 8770ms
No GCs detected
2022-11-24 19:00:03,632 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6352ms
No GCs detected
2022-11-25 07:00:03,607 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5865ms
No GCs detected
2022-12-04 16:35:44,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = MI104-08/172.31.18.37
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.10.2
STARTUP_MSG:   classpath = /travail/te131323/hadoop/hadoop-2.10.2/etc/hadoop:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-json-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-digester-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hadoop-annotations-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-net-3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/junit-4.13.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/zookeeper-3.4.14.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/httpcore-4.4.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/gson-2.2.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsp-api-2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/httpclient-4.5.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/activation-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/stax2-api-4.2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/spotbugs-annotations-3.1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hadoop-auth-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/json-smart-1.3.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsch-0.1.55.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jettison-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-nfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-common-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xercesImpl-2.12.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/netty-all-4.1.50.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xml-apis-1.4.01.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-databind-2.9.10.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-client-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/javax.inject-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/woodstox-core-5.3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/nimbus-jose-jwt-7.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/zookeeper-3.4.14.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-beanutils-1.9.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/audience-annotations-0.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/httpcore-4.4.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-framework-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/fst-2.50.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-client-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/httpclient-4.5.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/activation-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/stax2-api-4.2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-recipes-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/spotbugs-annotations-3.1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/json-smart-1.3.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsch-0.1.55.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guice-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jettison-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-router-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-registry-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-api-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/junit-4.13.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.10.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r 965fd380006fa78b2315668fbc7eb432e1d8200f; compiled by 'ubuntu' on 2022-05-24T22:35Z
STARTUP_MSG:   java = 1.8.0_333
************************************************************/
2022-12-04 16:35:44,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2022-12-04 16:35:44,771 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/travail/te131323/datadir/
2022-12-04 16:35:44,798 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2022-12-04 16:35:44,832 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2022-12-04 16:35:44,832 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2022-12-04 16:35:44,985 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-12-04 16:35:44,991 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2022-12-04 16:35:44,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is MI104-08
2022-12-04 16:35:44,993 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-12-04 16:35:44,993 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2022-12-04 16:35:44,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2022-12-04 16:35:45,004 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2022-12-04 16:35:45,005 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2022-12-04 16:35:45,005 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2022-12-04 16:35:45,051 INFO org.mortbay.log: Logging to org.slf4j.impl.Reload4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2022-12-04 16:35:45,055 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-12-04 16:35:45,057 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2022-12-04 16:35:45,060 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2022-12-04 16:35:45,061 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2022-12-04 16:35:45,061 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-12-04 16:35:45,061 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-12-04 16:35:45,093 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 38071
2022-12-04 16:35:45,093 INFO org.mortbay.log: jetty-6.1.26
2022-12-04 16:35:45,182 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:38071
2022-12-04 16:35:45,265 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2022-12-04 16:35:45,267 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2022-12-04 16:35:45,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = te131323
2022-12-04 16:35:45,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2022-12-04 16:35:45,286 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2022-12-04 16:35:45,292 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2022-12-04 16:35:45,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2022-12-04 16:35:45,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2022-12-04 16:35:45,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2022-12-04 16:35:45,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2022-12-04 16:35:45,351 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2022-12-04 16:35:45,351 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2022-12-04 16:35:45,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2022-12-04 16:35:45,459 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2022-12-04 16:35:45,461 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /travail/te131323/datadir/in_use.lock acquired by nodename 887407@MI104-08
2022-12-04 16:35:45,462 WARN org.apache.hadoop.hdfs.server.common.Storage: Failed to add storage directory [DISK]file:/travail/te131323/datadir/
java.io.IOException: Incompatible clusterIDs in /travail/te131323/datadir: namenode clusterID = CID-100472ac-5eab-4211-8bce-d1bcb81a9c0e; datanode clusterID = CID-a7af8c60-375a-4436-bea8-169fc18087fe
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:768)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadStorageDirectory(DataStorage.java:293)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadDataStorage(DataStorage.java:409)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:388)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:564)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1661)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1622)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:826)
	at java.lang.Thread.run(Thread.java:750)
2022-12-04 16:35:45,464 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid f2462099-cd02-473b-8fc9-c6a6551815ce) service to localhost/127.0.0.1:9000. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:565)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1661)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1622)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:826)
	at java.lang.Thread.run(Thread.java:750)
2022-12-04 16:35:45,464 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid f2462099-cd02-473b-8fc9-c6a6551815ce) service to localhost/127.0.0.1:9000
2022-12-04 16:35:45,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid f2462099-cd02-473b-8fc9-c6a6551815ce)
2022-12-04 16:35:47,475 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2022-12-04 16:35:47,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at MI104-08/172.31.18.37
************************************************************/
2022-12-12 20:21:40,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = MI104-08/172.31.18.37
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.10.2
STARTUP_MSG:   classpath = /travail/te131323/hadoop/hadoop-2.10.2/etc/hadoop:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-json-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-digester-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hadoop-annotations-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-net-3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/junit-4.13.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/zookeeper-3.4.14.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/httpcore-4.4.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/gson-2.2.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsp-api-2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/httpclient-4.5.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/activation-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/stax2-api-4.2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/spotbugs-annotations-3.1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hadoop-auth-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/json-smart-1.3.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsch-0.1.55.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jettison-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-nfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-common-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xercesImpl-2.12.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/netty-all-4.1.50.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xml-apis-1.4.01.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-databind-2.9.10.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-client-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/javax.inject-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/woodstox-core-5.3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/nimbus-jose-jwt-7.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/zookeeper-3.4.14.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-beanutils-1.9.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/audience-annotations-0.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/httpcore-4.4.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-framework-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/fst-2.50.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-client-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/httpclient-4.5.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/activation-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/stax2-api-4.2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-recipes-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/spotbugs-annotations-3.1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/json-smart-1.3.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsch-0.1.55.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guice-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jettison-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-router-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-registry-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-api-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/junit-4.13.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.10.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r 965fd380006fa78b2315668fbc7eb432e1d8200f; compiled by 'ubuntu' on 2022-05-24T22:35Z
STARTUP_MSG:   java = 1.8.0_333
************************************************************/
2022-12-12 20:21:40,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2022-12-12 20:21:40,725 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/travail/te131323/datadir/
2022-12-12 20:21:40,752 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2022-12-12 20:21:40,787 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2022-12-12 20:21:40,787 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2022-12-12 20:21:40,949 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-12-12 20:21:40,957 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2022-12-12 20:21:40,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is MI104-08
2022-12-12 20:21:40,959 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-12-12 20:21:40,959 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2022-12-12 20:21:40,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2022-12-12 20:21:40,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2022-12-12 20:21:40,971 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2022-12-12 20:21:40,971 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2022-12-12 20:21:41,020 INFO org.mortbay.log: Logging to org.slf4j.impl.Reload4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2022-12-12 20:21:41,024 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-12-12 20:21:41,026 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2022-12-12 20:21:41,029 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2022-12-12 20:21:41,030 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2022-12-12 20:21:41,030 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-12-12 20:21:41,030 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-12-12 20:21:41,064 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 41463
2022-12-12 20:21:41,064 INFO org.mortbay.log: jetty-6.1.26
2022-12-12 20:21:41,154 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:41463
2022-12-12 20:21:41,237 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2022-12-12 20:21:41,239 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2022-12-12 20:21:41,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = te131323
2022-12-12 20:21:41,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2022-12-12 20:21:41,257 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2022-12-12 20:21:41,264 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2022-12-12 20:21:41,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2022-12-12 20:21:41,320 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2022-12-12 20:21:41,324 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2022-12-12 20:21:41,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2022-12-12 20:21:41,331 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2022-12-12 20:21:41,331 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2022-12-12 20:21:41,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2022-12-12 20:21:41,440 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2022-12-12 20:21:41,442 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /travail/te131323/datadir/in_use.lock acquired by nodename 188229@MI104-08
2022-12-12 20:21:41,443 WARN org.apache.hadoop.hdfs.server.common.Storage: Failed to add storage directory [DISK]file:/travail/te131323/datadir/
java.io.IOException: Incompatible clusterIDs in /travail/te131323/datadir: namenode clusterID = CID-4088e6ef-1ee9-4a41-afc6-f22209f662ea; datanode clusterID = CID-a7af8c60-375a-4436-bea8-169fc18087fe
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:768)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadStorageDirectory(DataStorage.java:293)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadDataStorage(DataStorage.java:409)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:388)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:564)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1661)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1622)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:826)
	at java.lang.Thread.run(Thread.java:750)
2022-12-12 20:21:41,445 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid f2462099-cd02-473b-8fc9-c6a6551815ce) service to localhost/127.0.0.1:9000. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:565)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1661)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1622)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:826)
	at java.lang.Thread.run(Thread.java:750)
2022-12-12 20:21:41,445 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid f2462099-cd02-473b-8fc9-c6a6551815ce) service to localhost/127.0.0.1:9000
2022-12-12 20:21:41,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid f2462099-cd02-473b-8fc9-c6a6551815ce)
2022-12-12 20:21:43,456 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2022-12-12 20:21:43,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at MI104-08/172.31.18.37
************************************************************/
2022-12-12 20:30:38,732 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = MI104-08/172.31.18.37
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.10.2
STARTUP_MSG:   classpath = /travail/te131323/hadoop/hadoop-2.10.2/etc/hadoop:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-json-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-digester-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hadoop-annotations-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-net-3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/junit-4.13.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/zookeeper-3.4.14.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/httpcore-4.4.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/gson-2.2.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsp-api-2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/httpclient-4.5.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/activation-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/stax2-api-4.2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/spotbugs-annotations-3.1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hadoop-auth-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/json-smart-1.3.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsch-0.1.55.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jettison-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-nfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-common-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xercesImpl-2.12.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/netty-all-4.1.50.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xml-apis-1.4.01.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-databind-2.9.10.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-client-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/javax.inject-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/woodstox-core-5.3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/nimbus-jose-jwt-7.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/zookeeper-3.4.14.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-beanutils-1.9.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/audience-annotations-0.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/httpcore-4.4.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-framework-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/fst-2.50.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-client-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/httpclient-4.5.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/activation-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/stax2-api-4.2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-recipes-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/spotbugs-annotations-3.1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/json-smart-1.3.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsch-0.1.55.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guice-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jettison-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-router-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-registry-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-api-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/junit-4.13.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.10.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r 965fd380006fa78b2315668fbc7eb432e1d8200f; compiled by 'ubuntu' on 2022-05-24T22:35Z
STARTUP_MSG:   java = 1.8.0_333
************************************************************/
2022-12-12 20:30:38,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2022-12-12 20:30:38,940 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/travail/te131323/datadir/
2022-12-12 20:30:38,966 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2022-12-12 20:30:38,999 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2022-12-12 20:30:38,999 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2022-12-12 20:30:39,163 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-12-12 20:30:39,169 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2022-12-12 20:30:39,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is MI104-08
2022-12-12 20:30:39,171 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-12-12 20:30:39,171 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2022-12-12 20:30:39,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2022-12-12 20:30:39,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2022-12-12 20:30:39,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2022-12-12 20:30:39,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2022-12-12 20:30:39,228 INFO org.mortbay.log: Logging to org.slf4j.impl.Reload4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2022-12-12 20:30:39,231 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-12-12 20:30:39,234 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2022-12-12 20:30:39,236 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2022-12-12 20:30:39,237 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2022-12-12 20:30:39,237 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-12-12 20:30:39,237 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-12-12 20:30:39,269 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 39511
2022-12-12 20:30:39,269 INFO org.mortbay.log: jetty-6.1.26
2022-12-12 20:30:39,361 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:39511
2022-12-12 20:30:39,428 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2022-12-12 20:30:39,430 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2022-12-12 20:30:39,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = te131323
2022-12-12 20:30:39,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2022-12-12 20:30:39,447 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2022-12-12 20:30:39,453 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2022-12-12 20:30:39,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2022-12-12 20:30:39,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2022-12-12 20:30:39,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2022-12-12 20:30:39,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2022-12-12 20:30:39,508 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2022-12-12 20:30:39,508 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2022-12-12 20:30:39,560 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2022-12-12 20:30:39,561 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2022-12-12 20:30:39,564 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /travail/te131323/datadir/in_use.lock acquired by nodename 193478@MI104-08
2022-12-12 20:30:39,565 WARN org.apache.hadoop.hdfs.server.common.Storage: Failed to add storage directory [DISK]file:/travail/te131323/datadir/
java.io.IOException: Incompatible clusterIDs in /travail/te131323/datadir: namenode clusterID = CID-4088e6ef-1ee9-4a41-afc6-f22209f662ea; datanode clusterID = CID-a7af8c60-375a-4436-bea8-169fc18087fe
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:768)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadStorageDirectory(DataStorage.java:293)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadDataStorage(DataStorage.java:409)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:388)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:564)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1661)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1622)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:826)
	at java.lang.Thread.run(Thread.java:750)
2022-12-12 20:30:39,566 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid f2462099-cd02-473b-8fc9-c6a6551815ce) service to localhost/127.0.0.1:9000. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:565)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1661)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1622)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:826)
	at java.lang.Thread.run(Thread.java:750)
2022-12-12 20:30:39,566 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid f2462099-cd02-473b-8fc9-c6a6551815ce) service to localhost/127.0.0.1:9000
2022-12-12 20:30:39,576 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid f2462099-cd02-473b-8fc9-c6a6551815ce)
2022-12-12 20:30:41,577 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2022-12-12 20:30:41,583 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at MI104-08/172.31.18.37
************************************************************/
2022-12-15 14:47:56,673 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = MI104-08/172.31.18.37
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.10.2
STARTUP_MSG:   classpath = /travail/te131323/hadoop/hadoop-2.10.2/etc/hadoop:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-json-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-digester-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hadoop-annotations-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-net-3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/junit-4.13.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/zookeeper-3.4.14.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/httpcore-4.4.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/gson-2.2.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsp-api-2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/httpclient-4.5.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/activation-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/stax2-api-4.2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/spotbugs-annotations-3.1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hadoop-auth-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/json-smart-1.3.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsch-0.1.55.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jettison-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-nfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-common-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xercesImpl-2.12.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/netty-all-4.1.50.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xml-apis-1.4.01.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-databind-2.9.10.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-client-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/javax.inject-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/woodstox-core-5.3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/nimbus-jose-jwt-7.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/zookeeper-3.4.14.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-beanutils-1.9.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/audience-annotations-0.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/httpcore-4.4.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-framework-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/fst-2.50.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-client-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/httpclient-4.5.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/activation-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/stax2-api-4.2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-recipes-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/spotbugs-annotations-3.1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/json-smart-1.3.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsch-0.1.55.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guice-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jettison-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-router-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-registry-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-api-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/junit-4.13.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.10.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r 965fd380006fa78b2315668fbc7eb432e1d8200f; compiled by 'ubuntu' on 2022-05-24T22:35Z
STARTUP_MSG:   java = 1.8.0_333
************************************************************/
2022-12-15 14:47:56,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2022-12-15 14:47:56,891 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/travail/te131323/datadir/
2022-12-15 14:47:56,930 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2022-12-15 14:47:56,968 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2022-12-15 14:47:56,968 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2022-12-15 14:47:57,132 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-12-15 14:47:57,138 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2022-12-15 14:47:57,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is MI104-08
2022-12-15 14:47:57,139 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-12-15 14:47:57,139 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2022-12-15 14:47:57,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2022-12-15 14:47:57,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2022-12-15 14:47:57,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2022-12-15 14:47:57,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2022-12-15 14:47:57,186 INFO org.mortbay.log: Logging to org.slf4j.impl.Reload4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2022-12-15 14:47:57,190 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-12-15 14:47:57,192 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2022-12-15 14:47:57,194 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2022-12-15 14:47:57,195 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2022-12-15 14:47:57,195 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-12-15 14:47:57,195 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-12-15 14:47:57,227 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 34387
2022-12-15 14:47:57,227 INFO org.mortbay.log: jetty-6.1.26
2022-12-15 14:47:57,326 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:34387
2022-12-15 14:47:57,396 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2022-12-15 14:47:57,398 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2022-12-15 14:47:57,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = te131323
2022-12-15 14:47:57,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2022-12-15 14:47:57,416 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2022-12-15 14:47:57,423 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2022-12-15 14:47:57,476 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2022-12-15 14:47:57,484 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2022-12-15 14:47:57,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2022-12-15 14:47:57,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2022-12-15 14:47:57,498 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2022-12-15 14:47:57,498 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2022-12-15 14:47:57,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2022-12-15 14:47:57,552 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2022-12-15 14:47:57,555 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /travail/te131323/datadir/in_use.lock acquired by nodename 2326048@MI104-08
2022-12-15 14:47:57,556 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /travail/te131323/datadir is not formatted for namespace 1847433917. Formatting...
2022-12-15 14:47:57,556 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-62e624b5-a91e-48b1-8ff6-ba9e107b9aae for directory /travail/te131323/datadir
2022-12-15 14:47:57,569 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1903172506-172.31.18.37-1670872886548
2022-12-15 14:47:57,569 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /travail/te131323/datadir/current/BP-1903172506-172.31.18.37-1670872886548
2022-12-15 14:47:57,569 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /travail/te131323/datadir/current/BP-1903172506-172.31.18.37-1670872886548 is not formatted for BP-1903172506-172.31.18.37-1670872886548. Formatting ...
2022-12-15 14:47:57,569 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1903172506-172.31.18.37-1670872886548 directory /travail/te131323/datadir/current/BP-1903172506-172.31.18.37-1670872886548/current
2022-12-15 14:47:57,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1847433917;bpid=BP-1903172506-172.31.18.37-1670872886548;lv=-57;nsInfo=lv=-63;cid=CID-4088e6ef-1ee9-4a41-afc6-f22209f662ea;nsid=1847433917;c=1670872886548;bpid=BP-1903172506-172.31.18.37-1670872886548;dnuuid=null
2022-12-15 14:47:57,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 3c9f1c5b-94e9-4293-8e44-a34fc72182d7
2022-12-15 14:47:57,578 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.lock-reporting-threshold-ms(300) assuming MILLISECONDS
2022-12-15 14:47:57,588 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-62e624b5-a91e-48b1-8ff6-ba9e107b9aae
2022-12-15 14:47:57,588 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /travail/te131323/datadir/current, StorageType: DISK
2022-12-15 14:47:57,590 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2022-12-15 14:47:57,592 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /travail/te131323/datadir/current
2022-12-15 14:47:57,596 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /travail/te131323/datadir/current
2022-12-15 14:47:57,596 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1903172506-172.31.18.37-1670872886548
2022-12-15 14:47:57,597 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1903172506-172.31.18.37-1670872886548 on volume /travail/te131323/datadir/current...
2022-12-15 14:47:57,614 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1903172506-172.31.18.37-1670872886548 on /travail/te131323/datadir/current: 17ms
2022-12-15 14:47:57,614 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1903172506-172.31.18.37-1670872886548: 18ms
2022-12-15 14:47:57,615 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1903172506-172.31.18.37-1670872886548 on volume /travail/te131323/datadir/current...
2022-12-15 14:47:57,615 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /travail/te131323/datadir/current/BP-1903172506-172.31.18.37-1670872886548/current/replicas doesn't exist 
2022-12-15 14:47:57,616 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1903172506-172.31.18.37-1670872886548 on volume /travail/te131323/datadir/current: 0ms
2022-12-15 14:47:57,616 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-1903172506-172.31.18.37-1670872886548: 2ms
2022-12-15 14:47:57,617 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1903172506-172.31.18.37-1670872886548 on volume /travail/te131323/datadir
2022-12-15 14:47:57,617 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/travail/te131323/datadir, DS-62e624b5-a91e-48b1-8ff6-ba9e107b9aae): finished scanning block pool BP-1903172506-172.31.18.37-1670872886548
2022-12-15 14:47:57,619 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 15/12/22 17:01 with interval of 21600000ms
2022-12-15 14:47:57,620 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1903172506-172.31.18.37-1670872886548 (Datanode Uuid 3c9f1c5b-94e9-4293-8e44-a34fc72182d7) service to localhost/127.0.0.1:9000 beginning handshake with NN
2022-12-15 14:47:57,630 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/travail/te131323/datadir, DS-62e624b5-a91e-48b1-8ff6-ba9e107b9aae): no suitable block pools found to scan.  Waiting 1814399986 ms.
2022-12-15 14:47:57,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1903172506-172.31.18.37-1670872886548 (Datanode Uuid 3c9f1c5b-94e9-4293-8e44-a34fc72182d7) service to localhost/127.0.0.1:9000 successfully registered with NN
2022-12-15 14:47:57,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2022-12-15 14:47:57,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x7d74f09e1c4cccb7,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 21 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2022-12-15 14:47:57,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1903172506-172.31.18.37-1670872886548
2022-12-15 14:48:42,649 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "MI104-08/172.31.18.37"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:827)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:791)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1564)
	at org.apache.hadoop.ipc.Client.call(Client.java:1506)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy16.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:166)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:516)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:646)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:851)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1865)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
2022-12-15 14:48:46,646 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-12-15 14:48:46,771 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2022-12-15 14:48:46,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at MI104-08/172.31.18.37
************************************************************/
2022-12-15 14:49:19,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = MI104-08/172.31.18.37
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.10.2
STARTUP_MSG:   classpath = /travail/te131323/hadoop/hadoop-2.10.2/etc/hadoop:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-json-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-digester-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hadoop-annotations-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-net-3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/junit-4.13.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/zookeeper-3.4.14.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/httpcore-4.4.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/gson-2.2.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsp-api-2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/httpclient-4.5.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/activation-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/stax2-api-4.2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/spotbugs-annotations-3.1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hadoop-auth-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/json-smart-1.3.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsch-0.1.55.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jettison-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-nfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-common-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xercesImpl-2.12.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/netty-all-4.1.50.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xml-apis-1.4.01.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-databind-2.9.10.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-client-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/javax.inject-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/woodstox-core-5.3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/nimbus-jose-jwt-7.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/zookeeper-3.4.14.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-beanutils-1.9.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/audience-annotations-0.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/httpcore-4.4.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-framework-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/fst-2.50.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-client-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/httpclient-4.5.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/activation-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/stax2-api-4.2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-recipes-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/spotbugs-annotations-3.1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/json-smart-1.3.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsch-0.1.55.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guice-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jettison-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-router-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-registry-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-api-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/junit-4.13.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.10.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r 965fd380006fa78b2315668fbc7eb432e1d8200f; compiled by 'ubuntu' on 2022-05-24T22:35Z
STARTUP_MSG:   java = 1.8.0_333
************************************************************/
2022-12-15 14:49:19,134 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2022-12-15 14:49:19,348 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/travail/te131323/datadir/
2022-12-15 14:49:19,377 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2022-12-15 14:49:19,414 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2022-12-15 14:49:19,414 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2022-12-15 14:49:19,594 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-12-15 14:49:19,600 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2022-12-15 14:49:19,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is MI104-08
2022-12-15 14:49:19,602 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-12-15 14:49:19,602 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2022-12-15 14:49:19,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2022-12-15 14:49:19,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2022-12-15 14:49:19,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2022-12-15 14:49:19,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2022-12-15 14:49:19,662 INFO org.mortbay.log: Logging to org.slf4j.impl.Reload4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2022-12-15 14:49:19,665 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-12-15 14:49:19,668 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2022-12-15 14:49:19,670 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2022-12-15 14:49:19,671 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2022-12-15 14:49:19,671 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-12-15 14:49:19,671 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-12-15 14:49:19,704 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 33135
2022-12-15 14:49:19,704 INFO org.mortbay.log: jetty-6.1.26
2022-12-15 14:49:19,794 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:33135
2022-12-15 14:49:19,865 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2022-12-15 14:49:19,867 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2022-12-15 14:49:19,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = te131323
2022-12-15 14:49:19,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2022-12-15 14:49:19,885 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2022-12-15 14:49:19,891 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2022-12-15 14:49:19,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2022-12-15 14:49:19,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2022-12-15 14:49:19,951 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2022-12-15 14:49:19,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2022-12-15 14:49:19,959 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2022-12-15 14:49:19,959 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2022-12-15 14:49:20,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2022-12-15 14:49:20,066 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2022-12-15 14:49:20,069 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /travail/te131323/datadir/in_use.lock acquired by nodename 2329283@MI104-08
2022-12-15 14:49:20,070 WARN org.apache.hadoop.hdfs.server.common.Storage: Failed to add storage directory [DISK]file:/travail/te131323/datadir/
java.io.IOException: Incompatible clusterIDs in /travail/te131323/datadir: namenode clusterID = CID-72ac928a-511c-4ecd-a0db-940ad77a0cef; datanode clusterID = CID-4088e6ef-1ee9-4a41-afc6-f22209f662ea
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:768)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadStorageDirectory(DataStorage.java:293)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadDataStorage(DataStorage.java:409)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:388)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:564)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1661)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1622)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:826)
	at java.lang.Thread.run(Thread.java:750)
2022-12-15 14:49:20,071 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid 3c9f1c5b-94e9-4293-8e44-a34fc72182d7) service to localhost/127.0.0.1:9000. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:565)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1661)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1622)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:282)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:826)
	at java.lang.Thread.run(Thread.java:750)
2022-12-15 14:49:20,071 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid 3c9f1c5b-94e9-4293-8e44-a34fc72182d7) service to localhost/127.0.0.1:9000
2022-12-15 14:49:20,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid 3c9f1c5b-94e9-4293-8e44-a34fc72182d7)
2022-12-15 14:49:22,082 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2022-12-15 14:49:22,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at MI104-08/172.31.18.37
************************************************************/
2022-12-15 14:51:48,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = MI104-08/172.31.18.37
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.10.2
STARTUP_MSG:   classpath = /travail/te131323/hadoop/hadoop-2.10.2/etc/hadoop:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-json-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-digester-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hadoop-annotations-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-net-3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/junit-4.13.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/zookeeper-3.4.14.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/httpcore-4.4.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/gson-2.2.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsp-api-2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/httpclient-4.5.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/activation-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/stax2-api-4.2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/spotbugs-annotations-3.1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hadoop-auth-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/json-smart-1.3.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsch-0.1.55.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jettison-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-nfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-common-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xercesImpl-2.12.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/netty-all-4.1.50.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xml-apis-1.4.01.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-databind-2.9.10.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-client-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/javax.inject-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/woodstox-core-5.3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/nimbus-jose-jwt-7.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/zookeeper-3.4.14.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-beanutils-1.9.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/audience-annotations-0.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/httpcore-4.4.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-framework-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/fst-2.50.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-client-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/httpclient-4.5.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/activation-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/stax2-api-4.2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-recipes-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/spotbugs-annotations-3.1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/json-smart-1.3.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsch-0.1.55.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guice-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jettison-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-router-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-registry-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-api-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/junit-4.13.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.10.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r 965fd380006fa78b2315668fbc7eb432e1d8200f; compiled by 'ubuntu' on 2022-05-24T22:35Z
STARTUP_MSG:   java = 1.8.0_333
************************************************************/
2022-12-15 14:51:48,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2022-12-15 14:51:48,594 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/travail/te131323/datadir/
2022-12-15 14:51:48,635 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2022-12-15 14:51:48,672 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2022-12-15 14:51:48,672 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2022-12-15 14:51:48,834 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-12-15 14:51:48,840 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2022-12-15 14:51:48,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is MI104-08
2022-12-15 14:51:48,842 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-12-15 14:51:48,842 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2022-12-15 14:51:48,844 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2022-12-15 14:51:48,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2022-12-15 14:51:48,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2022-12-15 14:51:48,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2022-12-15 14:51:48,890 INFO org.mortbay.log: Logging to org.slf4j.impl.Reload4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2022-12-15 14:51:48,893 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-12-15 14:51:48,896 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2022-12-15 14:51:48,898 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2022-12-15 14:51:48,899 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2022-12-15 14:51:48,899 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-12-15 14:51:48,899 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-12-15 14:51:48,930 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 45233
2022-12-15 14:51:48,930 INFO org.mortbay.log: jetty-6.1.26
2022-12-15 14:51:49,017 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:45233
2022-12-15 14:51:49,086 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2022-12-15 14:51:49,088 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2022-12-15 14:51:49,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = te131323
2022-12-15 14:51:49,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2022-12-15 14:51:49,106 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2022-12-15 14:51:49,112 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2022-12-15 14:51:49,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2022-12-15 14:51:49,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2022-12-15 14:51:49,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2022-12-15 14:51:49,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2022-12-15 14:51:49,193 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2022-12-15 14:51:49,193 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2022-12-15 14:51:49,312 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2022-12-15 14:51:49,313 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2022-12-15 14:51:49,316 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /travail/te131323/datadir/in_use.lock acquired by nodename 2334774@MI104-08
2022-12-15 14:51:49,317 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /travail/te131323/datadir is not formatted for namespace 460937553. Formatting...
2022-12-15 14:51:49,317 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-02fa52ad-d78b-485a-b5bd-1c0690c99768 for directory /travail/te131323/datadir
2022-12-15 14:51:49,330 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1982133443-172.31.18.37-1671112294973
2022-12-15 14:51:49,330 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /travail/te131323/datadir/current/BP-1982133443-172.31.18.37-1671112294973
2022-12-15 14:51:49,330 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /travail/te131323/datadir/current/BP-1982133443-172.31.18.37-1671112294973 is not formatted for BP-1982133443-172.31.18.37-1671112294973. Formatting ...
2022-12-15 14:51:49,330 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1982133443-172.31.18.37-1671112294973 directory /travail/te131323/datadir/current/BP-1982133443-172.31.18.37-1671112294973/current
2022-12-15 14:51:49,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=460937553;bpid=BP-1982133443-172.31.18.37-1671112294973;lv=-57;nsInfo=lv=-63;cid=CID-85b5ee2b-da80-401c-99e3-e487e9bd0c43;nsid=460937553;c=1671112294973;bpid=BP-1982133443-172.31.18.37-1671112294973;dnuuid=null
2022-12-15 14:51:49,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID ec7ca47c-d341-4b79-8332-832482a46637
2022-12-15 14:51:49,339 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.lock-reporting-threshold-ms(300) assuming MILLISECONDS
2022-12-15 14:51:49,350 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-02fa52ad-d78b-485a-b5bd-1c0690c99768
2022-12-15 14:51:49,350 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /travail/te131323/datadir/current, StorageType: DISK
2022-12-15 14:51:49,352 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2022-12-15 14:51:49,355 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /travail/te131323/datadir/current
2022-12-15 14:51:49,358 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /travail/te131323/datadir/current
2022-12-15 14:51:49,359 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1982133443-172.31.18.37-1671112294973
2022-12-15 14:51:49,359 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1982133443-172.31.18.37-1671112294973 on volume /travail/te131323/datadir/current...
2022-12-15 14:51:49,375 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1982133443-172.31.18.37-1671112294973 on /travail/te131323/datadir/current: 16ms
2022-12-15 14:51:49,376 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1982133443-172.31.18.37-1671112294973: 16ms
2022-12-15 14:51:49,377 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1982133443-172.31.18.37-1671112294973 on volume /travail/te131323/datadir/current...
2022-12-15 14:51:49,377 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /travail/te131323/datadir/current/BP-1982133443-172.31.18.37-1671112294973/current/replicas doesn't exist 
2022-12-15 14:51:49,378 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1982133443-172.31.18.37-1671112294973 on volume /travail/te131323/datadir/current: 1ms
2022-12-15 14:51:49,378 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-1982133443-172.31.18.37-1671112294973: 2ms
2022-12-15 14:51:49,379 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1982133443-172.31.18.37-1671112294973 on volume /travail/te131323/datadir
2022-12-15 14:51:49,379 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/travail/te131323/datadir, DS-02fa52ad-d78b-485a-b5bd-1c0690c99768): finished scanning block pool BP-1982133443-172.31.18.37-1671112294973
2022-12-15 14:51:49,382 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 15/12/22 17:33 with interval of 21600000ms
2022-12-15 14:51:49,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1982133443-172.31.18.37-1671112294973 (Datanode Uuid ec7ca47c-d341-4b79-8332-832482a46637) service to localhost/127.0.0.1:9000 beginning handshake with NN
2022-12-15 14:51:49,391 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/travail/te131323/datadir, DS-02fa52ad-d78b-485a-b5bd-1c0690c99768): no suitable block pools found to scan.  Waiting 1814399988 ms.
2022-12-15 14:51:49,411 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1982133443-172.31.18.37-1671112294973 (Datanode Uuid ec7ca47c-d341-4b79-8332-832482a46637) service to localhost/127.0.0.1:9000 successfully registered with NN
2022-12-15 14:51:49,411 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2022-12-15 14:51:49,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x7ee7287d122da59d,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 28 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2022-12-15 14:51:49,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1982133443-172.31.18.37-1671112294973
2022-12-15 14:52:43,213 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1982133443-172.31.18.37-1671112294973:blk_1073741825_1001 src: /127.0.0.1:38922 dest: /127.0.0.1:50010
2022-12-15 14:52:43,229 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38922, dest: /127.0.0.1:50010, bytes: 40, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1840116226_1, offset: 0, srvID: ec7ca47c-d341-4b79-8332-832482a46637, blockid: BP-1982133443-172.31.18.37-1671112294973:blk_1073741825_1001, duration(ns): 6908349
2022-12-15 14:52:43,229 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1982133443-172.31.18.37-1671112294973:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2022-12-15 14:57:10,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1982133443-172.31.18.37-1671112294973:blk_1073741826_1002 src: /127.0.0.1:34338 dest: /127.0.0.1:50010
2022-12-15 14:57:10,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:34338, dest: /127.0.0.1:50010, bytes: 24, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-392161318_1, offset: 0, srvID: ec7ca47c-d341-4b79-8332-832482a46637, blockid: BP-1982133443-172.31.18.37-1671112294973:blk_1073741826_1002, duration(ns): 2992934
2022-12-15 14:57:10,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1982133443-172.31.18.37-1671112294973:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2022-12-15 15:01:50,210 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1982133443-172.31.18.37-1671112294973:blk_1073741827_1003 src: /127.0.0.1:49838 dest: /127.0.0.1:50010
2022-12-15 15:01:50,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49838, dest: /127.0.0.1:50010, bytes: 24, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1334760134_1, offset: 0, srvID: ec7ca47c-d341-4b79-8332-832482a46637, blockid: BP-1982133443-172.31.18.37-1671112294973:blk_1073741827_1003, duration(ns): 3158278
2022-12-15 15:01:50,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1982133443-172.31.18.37-1671112294973:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2022-12-15 15:04:26,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1982133443-172.31.18.37-1671112294973:blk_1073741828_1004 src: /127.0.0.1:60304 dest: /127.0.0.1:50010
2022-12-15 15:04:26,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60304, dest: /127.0.0.1:50010, bytes: 4, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-717096232_1, offset: 0, srvID: ec7ca47c-d341-4b79-8332-832482a46637, blockid: BP-1982133443-172.31.18.37-1671112294973:blk_1073741828_1004, duration(ns): 3105555
2022-12-15 15:04:26,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1982133443-172.31.18.37-1671112294973:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2022-12-15 15:05:30,933 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1982133443-172.31.18.37-1671112294973:blk_1073741829_1005 src: /127.0.0.1:35548 dest: /127.0.0.1:50010
2022-12-15 15:05:30,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:35548, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1595350572_1, offset: 0, srvID: ec7ca47c-d341-4b79-8332-832482a46637, blockid: BP-1982133443-172.31.18.37-1671112294973:blk_1073741829_1005, duration(ns): 3246823
2022-12-15 15:05:30,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1982133443-172.31.18.37-1671112294973:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2022-12-15 15:06:29,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1982133443-172.31.18.37-1671112294973:blk_1073741830_1006 src: /127.0.0.1:42196 dest: /127.0.0.1:50010
2022-12-15 15:06:29,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:42196, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1815173746_1, offset: 0, srvID: ec7ca47c-d341-4b79-8332-832482a46637, blockid: BP-1982133443-172.31.18.37-1671112294973:blk_1073741830_1006, duration(ns): 3086683
2022-12-15 15:06:29,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1982133443-172.31.18.37-1671112294973:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2022-12-15 15:07:57,590 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1982133443-172.31.18.37-1671112294973:blk_1073741831_1007 src: /127.0.0.1:47126 dest: /127.0.0.1:50010
2022-12-15 15:07:57,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:47126, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1531746526_1, offset: 0, srvID: ec7ca47c-d341-4b79-8332-832482a46637, blockid: BP-1982133443-172.31.18.37-1671112294973:blk_1073741831_1007, duration(ns): 3026036
2022-12-15 15:07:57,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1982133443-172.31.18.37-1671112294973:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2022-12-15 15:09:32,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1982133443-172.31.18.37-1671112294973:blk_1073741832_1008 src: /127.0.0.1:53984 dest: /127.0.0.1:50010
2022-12-15 15:09:32,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:53984, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-27218854_1, offset: 0, srvID: ec7ca47c-d341-4b79-8332-832482a46637, blockid: BP-1982133443-172.31.18.37-1671112294973:blk_1073741832_1008, duration(ns): 2742623
2022-12-15 15:09:32,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1982133443-172.31.18.37-1671112294973:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2022-12-15 15:12:35,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1982133443-172.31.18.37-1671112294973:blk_1073741833_1009 src: /127.0.0.1:36642 dest: /127.0.0.1:50010
2022-12-15 15:12:35,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:36642, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1225745025_1, offset: 0, srvID: ec7ca47c-d341-4b79-8332-832482a46637, blockid: BP-1982133443-172.31.18.37-1671112294973:blk_1073741833_1009, duration(ns): 3021807
2022-12-15 15:12:35,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1982133443-172.31.18.37-1671112294973:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2022-12-15 15:15:13,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1982133443-172.31.18.37-1671112294973:blk_1073741834_1010 src: /127.0.0.1:38224 dest: /127.0.0.1:50010
2022-12-15 15:15:13,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38224, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1947431212_1, offset: 0, srvID: ec7ca47c-d341-4b79-8332-832482a46637, blockid: BP-1982133443-172.31.18.37-1671112294973:blk_1073741834_1010, duration(ns): 3238367
2022-12-15 15:15:13,855 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1982133443-172.31.18.37-1671112294973:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2022-12-15 15:16:15,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1982133443-172.31.18.37-1671112294973:blk_1073741835_1011 src: /127.0.0.1:57300 dest: /127.0.0.1:50010
2022-12-15 15:16:15,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:57300, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-856774159_1, offset: 0, srvID: ec7ca47c-d341-4b79-8332-832482a46637, blockid: BP-1982133443-172.31.18.37-1671112294973:blk_1073741835_1011, duration(ns): 2940701
2022-12-15 15:16:15,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1982133443-172.31.18.37-1671112294973:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2022-12-15 15:19:49,337 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1982133443-172.31.18.37-1671112294973:blk_1073741836_1012 src: /127.0.0.1:34750 dest: /127.0.0.1:50010
2022-12-15 15:19:49,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:34750, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-579299414_1, offset: 0, srvID: ec7ca47c-d341-4b79-8332-832482a46637, blockid: BP-1982133443-172.31.18.37-1671112294973:blk_1073741836_1012, duration(ns): 3035208
2022-12-15 15:19:49,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1982133443-172.31.18.37-1671112294973:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2022-12-15 15:22:27,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1982133443-172.31.18.37-1671112294973:blk_1073741837_1013 src: /127.0.0.1:43244 dest: /127.0.0.1:50010
2022-12-15 15:22:27,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:43244, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-924038997_1, offset: 0, srvID: ec7ca47c-d341-4b79-8332-832482a46637, blockid: BP-1982133443-172.31.18.37-1671112294973:blk_1073741837_1013, duration(ns): 3885781
2022-12-15 15:22:27,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1982133443-172.31.18.37-1671112294973:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2022-12-15 15:23:23,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1982133443-172.31.18.37-1671112294973:blk_1073741838_1014 src: /127.0.0.1:60150 dest: /127.0.0.1:50010
2022-12-15 15:23:23,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60150, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-412362203_1, offset: 0, srvID: ec7ca47c-d341-4b79-8332-832482a46637, blockid: BP-1982133443-172.31.18.37-1671112294973:blk_1073741838_1014, duration(ns): 2825988
2022-12-15 15:23:23,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1982133443-172.31.18.37-1671112294973:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2022-12-15 15:44:40,503 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1982133443-172.31.18.37-1671112294973:blk_1073741839_1015 src: /127.0.0.1:36718 dest: /127.0.0.1:50010
2022-12-15 15:44:40,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:36718, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_922057811_1, offset: 0, srvID: ec7ca47c-d341-4b79-8332-832482a46637, blockid: BP-1982133443-172.31.18.37-1671112294973:blk_1073741839_1015, duration(ns): 3106361
2022-12-15 15:44:40,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1982133443-172.31.18.37-1671112294973:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2022-12-15 16:29:07,707 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "MI104-08/172.31.18.37"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:827)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:791)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1564)
	at org.apache.hadoop.ipc.Client.call(Client.java:1506)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy16.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:166)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:516)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:646)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:851)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1865)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
2022-12-15 16:29:11,705 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-12-15 16:29:12,299 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2022-12-15 16:29:12,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at MI104-08/172.31.18.37
************************************************************/
2022-12-15 16:30:43,383 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = MI104-08/172.31.18.37
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.10.2
STARTUP_MSG:   classpath = /travail/te131323/hadoop/hadoop-2.10.2/etc/hadoop:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-json-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-digester-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hadoop-annotations-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-net-3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/junit-4.13.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/zookeeper-3.4.14.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/httpcore-4.4.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/gson-2.2.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsp-api-2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/httpclient-4.5.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/activation-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/stax2-api-4.2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/spotbugs-annotations-3.1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hadoop-auth-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/json-smart-1.3.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsch-0.1.55.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jettison-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-nfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-common-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xercesImpl-2.12.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/netty-all-4.1.50.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xml-apis-1.4.01.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-databind-2.9.10.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-client-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/javax.inject-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/woodstox-core-5.3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/nimbus-jose-jwt-7.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/zookeeper-3.4.14.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-beanutils-1.9.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/audience-annotations-0.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/httpcore-4.4.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-framework-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/fst-2.50.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-client-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/httpclient-4.5.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/activation-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/stax2-api-4.2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-recipes-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/spotbugs-annotations-3.1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/json-smart-1.3.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsch-0.1.55.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guice-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jettison-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-router-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-registry-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-api-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/junit-4.13.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.10.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r 965fd380006fa78b2315668fbc7eb432e1d8200f; compiled by 'ubuntu' on 2022-05-24T22:35Z
STARTUP_MSG:   java = 1.8.0_333
************************************************************/
2022-12-15 16:30:43,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2022-12-15 16:30:43,595 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/travail/te131323/datadir/
2022-12-15 16:30:43,631 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2022-12-15 16:30:43,666 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2022-12-15 16:30:43,666 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2022-12-15 16:30:43,839 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-12-15 16:30:43,846 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2022-12-15 16:30:43,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is MI104-08
2022-12-15 16:30:43,847 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-12-15 16:30:43,847 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2022-12-15 16:30:43,849 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2022-12-15 16:30:43,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2022-12-15 16:30:43,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2022-12-15 16:30:43,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2022-12-15 16:30:43,897 INFO org.mortbay.log: Logging to org.slf4j.impl.Reload4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2022-12-15 16:30:43,901 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-12-15 16:30:43,903 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2022-12-15 16:30:43,906 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2022-12-15 16:30:43,907 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2022-12-15 16:30:43,907 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-12-15 16:30:43,907 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-12-15 16:30:43,937 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 34363
2022-12-15 16:30:43,937 INFO org.mortbay.log: jetty-6.1.26
2022-12-15 16:30:44,027 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:34363
2022-12-15 16:30:44,097 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2022-12-15 16:30:44,099 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2022-12-15 16:30:44,099 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = te131323
2022-12-15 16:30:44,099 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2022-12-15 16:30:44,117 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2022-12-15 16:30:44,123 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2022-12-15 16:30:44,163 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2022-12-15 16:30:44,169 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2022-12-15 16:30:44,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2022-12-15 16:30:44,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2022-12-15 16:30:44,180 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2022-12-15 16:30:44,180 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2022-12-15 16:30:44,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2022-12-15 16:30:44,293 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2022-12-15 16:30:44,295 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /travail/te131323/datadir/in_use.lock acquired by nodename 2463669@MI104-08
2022-12-15 16:30:44,296 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /travail/te131323/datadir is not formatted for namespace 492770424. Formatting...
2022-12-15 16:30:44,296 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-94cd009e-72be-4074-b13b-f01b0f166479 for directory /travail/te131323/datadir
2022-12-15 16:30:44,311 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1507797072-172.31.18.37-1671118229660
2022-12-15 16:30:44,311 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /travail/te131323/datadir/current/BP-1507797072-172.31.18.37-1671118229660
2022-12-15 16:30:44,311 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /travail/te131323/datadir/current/BP-1507797072-172.31.18.37-1671118229660 is not formatted for BP-1507797072-172.31.18.37-1671118229660. Formatting ...
2022-12-15 16:30:44,311 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1507797072-172.31.18.37-1671118229660 directory /travail/te131323/datadir/current/BP-1507797072-172.31.18.37-1671118229660/current
2022-12-15 16:30:44,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=492770424;bpid=BP-1507797072-172.31.18.37-1671118229660;lv=-57;nsInfo=lv=-63;cid=CID-737b7571-e7f0-430d-ba7a-bd5a1990f3f5;nsid=492770424;c=1671118229660;bpid=BP-1507797072-172.31.18.37-1671118229660;dnuuid=null
2022-12-15 16:30:44,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 917d2f88-8682-48a6-a44c-b42447b2c832
2022-12-15 16:30:44,321 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.lock-reporting-threshold-ms(300) assuming MILLISECONDS
2022-12-15 16:30:44,331 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-94cd009e-72be-4074-b13b-f01b0f166479
2022-12-15 16:30:44,331 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /travail/te131323/datadir/current, StorageType: DISK
2022-12-15 16:30:44,333 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2022-12-15 16:30:44,336 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /travail/te131323/datadir/current
2022-12-15 16:30:44,340 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /travail/te131323/datadir/current
2022-12-15 16:30:44,340 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1507797072-172.31.18.37-1671118229660
2022-12-15 16:30:44,341 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1507797072-172.31.18.37-1671118229660 on volume /travail/te131323/datadir/current...
2022-12-15 16:30:44,357 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1507797072-172.31.18.37-1671118229660 on /travail/te131323/datadir/current: 17ms
2022-12-15 16:30:44,357 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1507797072-172.31.18.37-1671118229660: 17ms
2022-12-15 16:30:44,359 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1507797072-172.31.18.37-1671118229660 on volume /travail/te131323/datadir/current...
2022-12-15 16:30:44,359 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /travail/te131323/datadir/current/BP-1507797072-172.31.18.37-1671118229660/current/replicas doesn't exist 
2022-12-15 16:30:44,359 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1507797072-172.31.18.37-1671118229660 on volume /travail/te131323/datadir/current: 1ms
2022-12-15 16:30:44,359 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-1507797072-172.31.18.37-1671118229660: 1ms
2022-12-15 16:30:44,360 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1507797072-172.31.18.37-1671118229660 on volume /travail/te131323/datadir
2022-12-15 16:30:44,361 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/travail/te131323/datadir, DS-94cd009e-72be-4074-b13b-f01b0f166479): finished scanning block pool BP-1507797072-172.31.18.37-1671118229660
2022-12-15 16:30:44,363 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 15/12/22 20:07 with interval of 21600000ms
2022-12-15 16:30:44,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1507797072-172.31.18.37-1671118229660 (Datanode Uuid 917d2f88-8682-48a6-a44c-b42447b2c832) service to localhost/127.0.0.1:9000 beginning handshake with NN
2022-12-15 16:30:44,372 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/travail/te131323/datadir, DS-94cd009e-72be-4074-b13b-f01b0f166479): no suitable block pools found to scan.  Waiting 1814399988 ms.
2022-12-15 16:30:44,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1507797072-172.31.18.37-1671118229660 (Datanode Uuid 917d2f88-8682-48a6-a44c-b42447b2c832) service to localhost/127.0.0.1:9000 successfully registered with NN
2022-12-15 16:30:44,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2022-12-15 16:30:44,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x63d3c4dde6634278,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 22 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2022-12-15 16:30:44,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1507797072-172.31.18.37-1671118229660
2022-12-15 16:31:39,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1507797072-172.31.18.37-1671118229660:blk_1073741825_1001 src: /127.0.0.1:58786 dest: /127.0.0.1:50010
2022-12-15 16:31:39,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:58786, dest: /127.0.0.1:50010, bytes: 40, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1166471484_1, offset: 0, srvID: 917d2f88-8682-48a6-a44c-b42447b2c832, blockid: BP-1507797072-172.31.18.37-1671118229660:blk_1073741825_1001, duration(ns): 6966169
2022-12-15 16:31:39,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1507797072-172.31.18.37-1671118229660:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2022-12-15 16:31:48,631 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1507797072-172.31.18.37-1671118229660:blk_1073741826_1002 src: /127.0.0.1:57770 dest: /127.0.0.1:50010
2022-12-15 16:31:48,635 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:57770, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_788797875_1, offset: 0, srvID: 917d2f88-8682-48a6-a44c-b42447b2c832, blockid: BP-1507797072-172.31.18.37-1671118229660:blk_1073741826_1002, duration(ns): 2846843
2022-12-15 16:31:48,635 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1507797072-172.31.18.37-1671118229660:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2022-12-15 16:36:39,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1507797072-172.31.18.37-1671118229660:blk_1073741827_1003 src: /127.0.0.1:37536 dest: /127.0.0.1:50010
2022-12-15 16:36:39,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:37536, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_361009682_1, offset: 0, srvID: 917d2f88-8682-48a6-a44c-b42447b2c832, blockid: BP-1507797072-172.31.18.37-1671118229660:blk_1073741827_1003, duration(ns): 2931507
2022-12-15 16:36:39,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1507797072-172.31.18.37-1671118229660:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2022-12-15 16:41:36,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1507797072-172.31.18.37-1671118229660:blk_1073741828_1004 src: /127.0.0.1:59780 dest: /127.0.0.1:50010
2022-12-15 16:41:36,534 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59780, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1360092272_1, offset: 0, srvID: 917d2f88-8682-48a6-a44c-b42447b2c832, blockid: BP-1507797072-172.31.18.37-1671118229660:blk_1073741828_1004, duration(ns): 3429548
2022-12-15 16:41:36,534 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1507797072-172.31.18.37-1671118229660:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2022-12-15 16:43:50,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1507797072-172.31.18.37-1671118229660:blk_1073741829_1005 src: /127.0.0.1:35004 dest: /127.0.0.1:50010
2022-12-15 16:43:50,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:35004, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1515546985_1, offset: 0, srvID: 917d2f88-8682-48a6-a44c-b42447b2c832, blockid: BP-1507797072-172.31.18.37-1671118229660:blk_1073741829_1005, duration(ns): 3179710
2022-12-15 16:43:50,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1507797072-172.31.18.37-1671118229660:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2022-12-15 16:44:12,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1507797072-172.31.18.37-1671118229660:blk_1073741830_1006 src: /127.0.0.1:33184 dest: /127.0.0.1:50010
2022-12-15 16:44:12,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:33184, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2076016715_1, offset: 0, srvID: 917d2f88-8682-48a6-a44c-b42447b2c832, blockid: BP-1507797072-172.31.18.37-1671118229660:blk_1073741830_1006, duration(ns): 2921185
2022-12-15 16:44:12,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1507797072-172.31.18.37-1671118229660:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2022-12-15 16:45:11,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1507797072-172.31.18.37-1671118229660:blk_1073741831_1007 src: /127.0.0.1:38554 dest: /127.0.0.1:50010
2022-12-15 16:45:11,803 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38554, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_639122821_1, offset: 0, srvID: 917d2f88-8682-48a6-a44c-b42447b2c832, blockid: BP-1507797072-172.31.18.37-1671118229660:blk_1073741831_1007, duration(ns): 2916637
2022-12-15 16:45:11,803 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1507797072-172.31.18.37-1671118229660:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2022-12-15 16:47:59,113 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1507797072-172.31.18.37-1671118229660:blk_1073741832_1008 src: /127.0.0.1:53584 dest: /127.0.0.1:50010
2022-12-15 16:47:59,116 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:53584, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-180117482_1, offset: 0, srvID: 917d2f88-8682-48a6-a44c-b42447b2c832, blockid: BP-1507797072-172.31.18.37-1671118229660:blk_1073741832_1008, duration(ns): 2826368
2022-12-15 16:47:59,116 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1507797072-172.31.18.37-1671118229660:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2022-12-15 16:52:12,047 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1507797072-172.31.18.37-1671118229660:blk_1073741833_1009 src: /127.0.0.1:54470 dest: /127.0.0.1:50010
2022-12-15 16:52:12,051 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:54470, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1073521587_1, offset: 0, srvID: 917d2f88-8682-48a6-a44c-b42447b2c832, blockid: BP-1507797072-172.31.18.37-1671118229660:blk_1073741833_1009, duration(ns): 2865430
2022-12-15 16:52:12,051 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1507797072-172.31.18.37-1671118229660:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2022-12-15 17:05:15,411 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1507797072-172.31.18.37-1671118229660:blk_1073741834_1010 src: /127.0.0.1:36086 dest: /127.0.0.1:50010
2022-12-15 17:05:15,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:36086, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_372177569_1, offset: 0, srvID: 917d2f88-8682-48a6-a44c-b42447b2c832, blockid: BP-1507797072-172.31.18.37-1671118229660:blk_1073741834_1010, duration(ns): 3252236
2022-12-15 17:05:15,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1507797072-172.31.18.37-1671118229660:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2022-12-15 17:06:39,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1507797072-172.31.18.37-1671118229660:blk_1073741835_1011 src: /127.0.0.1:40432 dest: /127.0.0.1:50010
2022-12-15 17:06:39,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:40432, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1653891179_1, offset: 0, srvID: 917d2f88-8682-48a6-a44c-b42447b2c832, blockid: BP-1507797072-172.31.18.37-1671118229660:blk_1073741835_1011, duration(ns): 2873280
2022-12-15 17:06:39,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1507797072-172.31.18.37-1671118229660:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2022-12-15 17:08:05,702 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1507797072-172.31.18.37-1671118229660:blk_1073741836_1012 src: /127.0.0.1:57516 dest: /127.0.0.1:50010
2022-12-15 17:08:05,706 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:57516, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-739756033_1, offset: 0, srvID: 917d2f88-8682-48a6-a44c-b42447b2c832, blockid: BP-1507797072-172.31.18.37-1671118229660:blk_1073741836_1012, duration(ns): 2832513
2022-12-15 17:08:05,706 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1507797072-172.31.18.37-1671118229660:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2022-12-15 17:09:26,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1507797072-172.31.18.37-1671118229660:blk_1073741837_1013 src: /127.0.0.1:42752 dest: /127.0.0.1:50010
2022-12-15 17:09:26,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:42752, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_598011078_1, offset: 0, srvID: 917d2f88-8682-48a6-a44c-b42447b2c832, blockid: BP-1507797072-172.31.18.37-1671118229660:blk_1073741837_1013, duration(ns): 3138735
2022-12-15 17:09:26,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1507797072-172.31.18.37-1671118229660:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2022-12-15 17:14:32,543 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "MI104-08/172.31.18.37"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:827)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:791)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1564)
	at org.apache.hadoop.ipc.Client.call(Client.java:1506)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy16.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:166)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:516)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:646)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:851)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1865)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
2022-12-15 17:14:36,544 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-12-15 17:14:37,299 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2022-12-15 17:14:37,303 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at MI104-08/172.31.18.37
************************************************************/
2022-12-15 18:16:25,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = MI104-08/172.31.18.37
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.10.2
STARTUP_MSG:   classpath = /travail/te131323/hadoop/hadoop-2.10.2/etc/hadoop:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-json-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-digester-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hadoop-annotations-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-net-3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/junit-4.13.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/zookeeper-3.4.14.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/httpcore-4.4.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/gson-2.2.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsp-api-2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/httpclient-4.5.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/activation-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/stax2-api-4.2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/spotbugs-annotations-3.1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hadoop-auth-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/json-smart-1.3.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsch-0.1.55.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jettison-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-nfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-common-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xercesImpl-2.12.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/netty-all-4.1.50.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xml-apis-1.4.01.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-databind-2.9.10.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-client-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/javax.inject-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/woodstox-core-5.3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/nimbus-jose-jwt-7.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/zookeeper-3.4.14.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-beanutils-1.9.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/audience-annotations-0.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/httpcore-4.4.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-framework-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/fst-2.50.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-client-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/httpclient-4.5.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/activation-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/stax2-api-4.2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-recipes-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/spotbugs-annotations-3.1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/json-smart-1.3.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsch-0.1.55.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guice-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jettison-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-router-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-registry-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-api-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/junit-4.13.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.10.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r 965fd380006fa78b2315668fbc7eb432e1d8200f; compiled by 'ubuntu' on 2022-05-24T22:35Z
STARTUP_MSG:   java = 1.8.0_333
************************************************************/
2022-12-15 18:16:25,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2022-12-15 18:16:25,756 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/travail/te131323/datadir/
2022-12-15 18:16:25,792 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2022-12-15 18:16:25,830 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2022-12-15 18:16:25,830 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2022-12-15 18:16:25,990 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-12-15 18:16:25,996 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2022-12-15 18:16:25,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is MI104-08
2022-12-15 18:16:25,997 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-12-15 18:16:25,997 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2022-12-15 18:16:25,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2022-12-15 18:16:26,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2022-12-15 18:16:26,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2022-12-15 18:16:26,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2022-12-15 18:16:26,045 INFO org.mortbay.log: Logging to org.slf4j.impl.Reload4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2022-12-15 18:16:26,048 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-12-15 18:16:26,051 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2022-12-15 18:16:26,053 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2022-12-15 18:16:26,054 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2022-12-15 18:16:26,054 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-12-15 18:16:26,054 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-12-15 18:16:26,088 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 36909
2022-12-15 18:16:26,088 INFO org.mortbay.log: jetty-6.1.26
2022-12-15 18:16:26,183 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:36909
2022-12-15 18:16:26,254 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2022-12-15 18:16:26,257 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2022-12-15 18:16:26,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = te131323
2022-12-15 18:16:26,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2022-12-15 18:16:26,275 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2022-12-15 18:16:26,281 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2022-12-15 18:16:26,328 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2022-12-15 18:16:26,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2022-12-15 18:16:26,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2022-12-15 18:16:26,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2022-12-15 18:16:26,349 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2022-12-15 18:16:26,349 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2022-12-15 18:16:26,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2022-12-15 18:16:26,460 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2022-12-15 18:16:26,463 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /travail/te131323/datadir/in_use.lock acquired by nodename 2594660@MI104-08
2022-12-15 18:16:26,463 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /travail/te131323/datadir is not formatted for namespace 1397728796. Formatting...
2022-12-15 18:16:26,463 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-1f458463-d314-4950-ab1a-153e0f9c7f16 for directory /travail/te131323/datadir
2022-12-15 18:16:26,477 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1699341340-172.31.18.37-1671124574854
2022-12-15 18:16:26,477 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /travail/te131323/datadir/current/BP-1699341340-172.31.18.37-1671124574854
2022-12-15 18:16:26,477 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /travail/te131323/datadir/current/BP-1699341340-172.31.18.37-1671124574854 is not formatted for BP-1699341340-172.31.18.37-1671124574854. Formatting ...
2022-12-15 18:16:26,477 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1699341340-172.31.18.37-1671124574854 directory /travail/te131323/datadir/current/BP-1699341340-172.31.18.37-1671124574854/current
2022-12-15 18:16:26,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1397728796;bpid=BP-1699341340-172.31.18.37-1671124574854;lv=-57;nsInfo=lv=-63;cid=CID-3e88a7ad-e6ef-4a40-9a17-0d26b9bdb4e2;nsid=1397728796;c=1671124574854;bpid=BP-1699341340-172.31.18.37-1671124574854;dnuuid=null
2022-12-15 18:16:26,479 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID a7b7dd28-88b0-4d72-a6c6-3e98df3925ad
2022-12-15 18:16:26,486 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.lock-reporting-threshold-ms(300) assuming MILLISECONDS
2022-12-15 18:16:26,496 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-1f458463-d314-4950-ab1a-153e0f9c7f16
2022-12-15 18:16:26,497 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /travail/te131323/datadir/current, StorageType: DISK
2022-12-15 18:16:26,498 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2022-12-15 18:16:26,501 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /travail/te131323/datadir/current
2022-12-15 18:16:26,505 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /travail/te131323/datadir/current
2022-12-15 18:16:26,505 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1699341340-172.31.18.37-1671124574854
2022-12-15 18:16:26,506 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1699341340-172.31.18.37-1671124574854 on volume /travail/te131323/datadir/current...
2022-12-15 18:16:26,522 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1699341340-172.31.18.37-1671124574854 on /travail/te131323/datadir/current: 17ms
2022-12-15 18:16:26,522 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1699341340-172.31.18.37-1671124574854: 17ms
2022-12-15 18:16:26,523 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1699341340-172.31.18.37-1671124574854 on volume /travail/te131323/datadir/current...
2022-12-15 18:16:26,523 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /travail/te131323/datadir/current/BP-1699341340-172.31.18.37-1671124574854/current/replicas doesn't exist 
2022-12-15 18:16:26,524 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1699341340-172.31.18.37-1671124574854 on volume /travail/te131323/datadir/current: 1ms
2022-12-15 18:16:26,524 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-1699341340-172.31.18.37-1671124574854: 2ms
2022-12-15 18:16:26,525 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1699341340-172.31.18.37-1671124574854 on volume /travail/te131323/datadir
2022-12-15 18:16:26,525 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/travail/te131323/datadir, DS-1f458463-d314-4950-ab1a-153e0f9c7f16): finished scanning block pool BP-1699341340-172.31.18.37-1671124574854
2022-12-15 18:16:26,528 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 15/12/22 22:11 with interval of 21600000ms
2022-12-15 18:16:26,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1699341340-172.31.18.37-1671124574854 (Datanode Uuid a7b7dd28-88b0-4d72-a6c6-3e98df3925ad) service to localhost/127.0.0.1:9000 beginning handshake with NN
2022-12-15 18:16:26,539 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/travail/te131323/datadir, DS-1f458463-d314-4950-ab1a-153e0f9c7f16): no suitable block pools found to scan.  Waiting 1814399986 ms.
2022-12-15 18:16:26,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1699341340-172.31.18.37-1671124574854 (Datanode Uuid a7b7dd28-88b0-4d72-a6c6-3e98df3925ad) service to localhost/127.0.0.1:9000 successfully registered with NN
2022-12-15 18:16:26,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2022-12-15 18:16:26,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x5a33b4316ae587e8,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 23 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2022-12-15 18:16:26,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1699341340-172.31.18.37-1671124574854
2022-12-15 18:17:23,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699341340-172.31.18.37-1671124574854:blk_1073741825_1001 src: /127.0.0.1:53950 dest: /127.0.0.1:50010
2022-12-15 18:17:23,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:53950, dest: /127.0.0.1:50010, bytes: 40, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2006398106_1, offset: 0, srvID: a7b7dd28-88b0-4d72-a6c6-3e98df3925ad, blockid: BP-1699341340-172.31.18.37-1671124574854:blk_1073741825_1001, duration(ns): 8721119
2022-12-15 18:17:23,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699341340-172.31.18.37-1671124574854:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2022-12-15 18:17:31,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699341340-172.31.18.37-1671124574854:blk_1073741826_1002 src: /127.0.0.1:56608 dest: /127.0.0.1:50010
2022-12-15 18:17:31,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56608, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1451272267_1, offset: 0, srvID: a7b7dd28-88b0-4d72-a6c6-3e98df3925ad, blockid: BP-1699341340-172.31.18.37-1671124574854:blk_1073741826_1002, duration(ns): 4172430
2022-12-15 18:17:31,887 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699341340-172.31.18.37-1671124574854:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2022-12-15 18:29:05,400 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699341340-172.31.18.37-1671124574854:blk_1073741827_1003 src: /127.0.0.1:34914 dest: /127.0.0.1:50010
2022-12-15 18:29:05,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:34914, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_401100522_1, offset: 0, srvID: a7b7dd28-88b0-4d72-a6c6-3e98df3925ad, blockid: BP-1699341340-172.31.18.37-1671124574854:blk_1073741827_1003, duration(ns): 2812144
2022-12-15 18:29:05,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699341340-172.31.18.37-1671124574854:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2022-12-15 18:30:44,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699341340-172.31.18.37-1671124574854:blk_1073741828_1004 src: /127.0.0.1:36874 dest: /127.0.0.1:50010
2022-12-15 18:30:44,582 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:36874, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_25438705_1, offset: 0, srvID: a7b7dd28-88b0-4d72-a6c6-3e98df3925ad, blockid: BP-1699341340-172.31.18.37-1671124574854:blk_1073741828_1004, duration(ns): 3239200
2022-12-15 18:30:44,582 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699341340-172.31.18.37-1671124574854:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2022-12-15 18:32:00,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699341340-172.31.18.37-1671124574854:blk_1073741829_1005 src: /127.0.0.1:51528 dest: /127.0.0.1:50010
2022-12-15 18:32:00,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:51528, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_502845729_1, offset: 0, srvID: a7b7dd28-88b0-4d72-a6c6-3e98df3925ad, blockid: BP-1699341340-172.31.18.37-1671124574854:blk_1073741829_1005, duration(ns): 3025200
2022-12-15 18:32:00,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699341340-172.31.18.37-1671124574854:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2022-12-15 18:33:54,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699341340-172.31.18.37-1671124574854:blk_1073741830_1006 src: /127.0.0.1:50576 dest: /127.0.0.1:50010
2022-12-15 18:33:54,425 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50576, dest: /127.0.0.1:50010, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-675173232_1, offset: 0, srvID: a7b7dd28-88b0-4d72-a6c6-3e98df3925ad, blockid: BP-1699341340-172.31.18.37-1671124574854:blk_1073741830_1006, duration(ns): 3131199
2022-12-15 18:33:54,425 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699341340-172.31.18.37-1671124574854:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2022-12-15 18:38:04,425 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699341340-172.31.18.37-1671124574854:blk_1073741831_1007 src: /127.0.0.1:57378 dest: /127.0.0.1:50010
2022-12-15 18:38:04,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:57378, dest: /127.0.0.1:50010, bytes: 48, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2118072549_1, offset: 0, srvID: a7b7dd28-88b0-4d72-a6c6-3e98df3925ad, blockid: BP-1699341340-172.31.18.37-1671124574854:blk_1073741831_1007, duration(ns): 4775740
2022-12-15 18:38:04,431 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699341340-172.31.18.37-1671124574854:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2022-12-15 18:40:25,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699341340-172.31.18.37-1671124574854:blk_1073741832_1008 src: /127.0.0.1:33842 dest: /127.0.0.1:50010
2022-12-15 18:40:25,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:33842, dest: /127.0.0.1:50010, bytes: 25, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1830895634_1, offset: 0, srvID: a7b7dd28-88b0-4d72-a6c6-3e98df3925ad, blockid: BP-1699341340-172.31.18.37-1671124574854:blk_1073741832_1008, duration(ns): 3264023
2022-12-15 18:40:25,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699341340-172.31.18.37-1671124574854:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2022-12-15 18:43:49,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699341340-172.31.18.37-1671124574854:blk_1073741833_1009 src: /127.0.0.1:47706 dest: /127.0.0.1:50010
2022-12-15 18:43:49,516 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:47706, dest: /127.0.0.1:50010, bytes: 25, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1129262725_1, offset: 0, srvID: a7b7dd28-88b0-4d72-a6c6-3e98df3925ad, blockid: BP-1699341340-172.31.18.37-1671124574854:blk_1073741833_1009, duration(ns): 3226543
2022-12-15 18:43:49,517 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699341340-172.31.18.37-1671124574854:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2022-12-15 18:46:01,662 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699341340-172.31.18.37-1671124574854:blk_1073741834_1010 src: /127.0.0.1:39324 dest: /127.0.0.1:50010
2022-12-15 18:46:01,666 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:39324, dest: /127.0.0.1:50010, bytes: 25, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1104403499_1, offset: 0, srvID: a7b7dd28-88b0-4d72-a6c6-3e98df3925ad, blockid: BP-1699341340-172.31.18.37-1671124574854:blk_1073741834_1010, duration(ns): 2968922
2022-12-15 18:46:01,666 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699341340-172.31.18.37-1671124574854:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2022-12-15 18:56:59,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699341340-172.31.18.37-1671124574854:blk_1073741835_1011 src: /127.0.0.1:55456 dest: /127.0.0.1:50010
2022-12-15 18:56:59,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55456, dest: /127.0.0.1:50010, bytes: 25, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_348493919_1, offset: 0, srvID: a7b7dd28-88b0-4d72-a6c6-3e98df3925ad, blockid: BP-1699341340-172.31.18.37-1671124574854:blk_1073741835_1011, duration(ns): 2797387
2022-12-15 18:56:59,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699341340-172.31.18.37-1671124574854:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2022-12-15 18:57:36,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1699341340-172.31.18.37-1671124574854:blk_1073741836_1012 src: /127.0.0.1:45278 dest: /127.0.0.1:50010
2022-12-15 18:57:36,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:45278, dest: /127.0.0.1:50010, bytes: 25, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2049866760_1, offset: 0, srvID: a7b7dd28-88b0-4d72-a6c6-3e98df3925ad, blockid: BP-1699341340-172.31.18.37-1671124574854:blk_1073741836_1012, duration(ns): 2756360
2022-12-15 18:57:36,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1699341340-172.31.18.37-1671124574854:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2022-12-15 18:58:11,684 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "MI104-08/172.31.18.37"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:827)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:791)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1564)
	at org.apache.hadoop.ipc.Client.call(Client.java:1506)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy16.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:166)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:516)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:646)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:851)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1865)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
2022-12-15 18:58:14,823 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2022-12-15 18:58:14,824 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at MI104-08/172.31.18.37
************************************************************/
2022-12-16 11:02:46,682 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = MI104-08/172.31.18.37
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.10.2
STARTUP_MSG:   classpath = /travail/te131323/hadoop/hadoop-2.10.2/etc/hadoop:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-json-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-digester-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hadoop-annotations-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-net-3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/junit-4.13.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/zookeeper-3.4.14.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/httpcore-4.4.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/gson-2.2.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsp-api-2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/httpclient-4.5.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/activation-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/stax2-api-4.2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/spotbugs-annotations-3.1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hadoop-auth-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/json-smart-1.3.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsch-0.1.55.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jettison-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-nfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-common-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xercesImpl-2.12.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/netty-all-4.1.50.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xml-apis-1.4.01.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-databind-2.9.10.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-client-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/javax.inject-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/woodstox-core-5.3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/nimbus-jose-jwt-7.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/zookeeper-3.4.14.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-beanutils-1.9.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/audience-annotations-0.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/httpcore-4.4.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-framework-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/fst-2.50.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-client-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/httpclient-4.5.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/activation-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/stax2-api-4.2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-recipes-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/spotbugs-annotations-3.1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/json-smart-1.3.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsch-0.1.55.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guice-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jettison-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-router-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-registry-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-api-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/junit-4.13.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.10.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r 965fd380006fa78b2315668fbc7eb432e1d8200f; compiled by 'ubuntu' on 2022-05-24T22:35Z
STARTUP_MSG:   java = 1.8.0_333
************************************************************/
2022-12-16 11:02:46,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2022-12-16 11:02:46,926 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/travail/te131323/datadir/
2022-12-16 11:02:46,967 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2022-12-16 11:02:47,009 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2022-12-16 11:02:47,009 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2022-12-16 11:02:47,197 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-12-16 11:02:47,204 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2022-12-16 11:02:47,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is MI104-08
2022-12-16 11:02:47,206 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-12-16 11:02:47,206 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2022-12-16 11:02:47,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2022-12-16 11:02:47,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2022-12-16 11:02:47,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2022-12-16 11:02:47,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2022-12-16 11:02:47,254 INFO org.mortbay.log: Logging to org.slf4j.impl.Reload4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2022-12-16 11:02:47,257 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-12-16 11:02:47,260 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2022-12-16 11:02:47,262 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2022-12-16 11:02:47,263 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2022-12-16 11:02:47,263 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-12-16 11:02:47,263 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-12-16 11:02:47,296 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 40843
2022-12-16 11:02:47,296 INFO org.mortbay.log: jetty-6.1.26
2022-12-16 11:02:47,392 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:40843
2022-12-16 11:02:47,461 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2022-12-16 11:02:47,464 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2022-12-16 11:02:47,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = te131323
2022-12-16 11:02:47,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2022-12-16 11:02:47,481 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2022-12-16 11:02:47,489 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2022-12-16 11:02:47,541 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2022-12-16 11:02:47,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2022-12-16 11:02:47,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2022-12-16 11:02:47,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2022-12-16 11:02:47,559 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2022-12-16 11:02:47,559 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2022-12-16 11:02:47,666 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2022-12-16 11:02:47,666 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2022-12-16 11:02:47,669 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /travail/te131323/datadir/in_use.lock acquired by nodename 3670272@MI104-08
2022-12-16 11:02:47,670 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /travail/te131323/datadir is not formatted for namespace 2057227758. Formatting...
2022-12-16 11:02:47,670 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-d7e1160e-888d-4d5a-a131-a614a39c2563 for directory /travail/te131323/datadir
2022-12-16 11:02:47,683 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-2103221849-172.31.18.37-1671184955276
2022-12-16 11:02:47,683 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /travail/te131323/datadir/current/BP-2103221849-172.31.18.37-1671184955276
2022-12-16 11:02:47,683 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /travail/te131323/datadir/current/BP-2103221849-172.31.18.37-1671184955276 is not formatted for BP-2103221849-172.31.18.37-1671184955276. Formatting ...
2022-12-16 11:02:47,683 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-2103221849-172.31.18.37-1671184955276 directory /travail/te131323/datadir/current/BP-2103221849-172.31.18.37-1671184955276/current
2022-12-16 11:02:47,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=2057227758;bpid=BP-2103221849-172.31.18.37-1671184955276;lv=-57;nsInfo=lv=-63;cid=CID-db7cba9f-8cad-431e-ac0f-8423315b449c;nsid=2057227758;c=1671184955276;bpid=BP-2103221849-172.31.18.37-1671184955276;dnuuid=null
2022-12-16 11:02:47,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID d2ef27b5-5432-4b03-a94f-ad62c09e634e
2022-12-16 11:02:47,692 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.lock-reporting-threshold-ms(300) assuming MILLISECONDS
2022-12-16 11:02:47,702 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-d7e1160e-888d-4d5a-a131-a614a39c2563
2022-12-16 11:02:47,702 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /travail/te131323/datadir/current, StorageType: DISK
2022-12-16 11:02:47,704 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2022-12-16 11:02:47,706 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /travail/te131323/datadir/current
2022-12-16 11:02:47,710 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /travail/te131323/datadir/current
2022-12-16 11:02:47,710 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-2103221849-172.31.18.37-1671184955276
2022-12-16 11:02:47,711 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-2103221849-172.31.18.37-1671184955276 on volume /travail/te131323/datadir/current...
2022-12-16 11:02:47,727 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-2103221849-172.31.18.37-1671184955276 on /travail/te131323/datadir/current: 16ms
2022-12-16 11:02:47,727 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-2103221849-172.31.18.37-1671184955276: 17ms
2022-12-16 11:02:47,728 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-2103221849-172.31.18.37-1671184955276 on volume /travail/te131323/datadir/current...
2022-12-16 11:02:47,728 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /travail/te131323/datadir/current/BP-2103221849-172.31.18.37-1671184955276/current/replicas doesn't exist 
2022-12-16 11:02:47,729 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-2103221849-172.31.18.37-1671184955276 on volume /travail/te131323/datadir/current: 1ms
2022-12-16 11:02:47,729 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-2103221849-172.31.18.37-1671184955276: 1ms
2022-12-16 11:02:47,730 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-2103221849-172.31.18.37-1671184955276 on volume /travail/te131323/datadir
2022-12-16 11:02:47,730 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/travail/te131323/datadir, DS-d7e1160e-888d-4d5a-a131-a614a39c2563): finished scanning block pool BP-2103221849-172.31.18.37-1671184955276
2022-12-16 11:02:47,733 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 16/12/22 14:11 with interval of 21600000ms
2022-12-16 11:02:47,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-2103221849-172.31.18.37-1671184955276 (Datanode Uuid d2ef27b5-5432-4b03-a94f-ad62c09e634e) service to localhost/127.0.0.1:9000 beginning handshake with NN
2022-12-16 11:02:47,744 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/travail/te131323/datadir, DS-d7e1160e-888d-4d5a-a131-a614a39c2563): no suitable block pools found to scan.  Waiting 1814399986 ms.
2022-12-16 11:02:47,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-2103221849-172.31.18.37-1671184955276 (Datanode Uuid d2ef27b5-5432-4b03-a94f-ad62c09e634e) service to localhost/127.0.0.1:9000 successfully registered with NN
2022-12-16 11:02:47,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2022-12-16 11:02:47,829 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x721da2f65dcea621,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 22 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2022-12-16 11:02:47,829 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-2103221849-172.31.18.37-1671184955276
2022-12-16 11:03:37,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2103221849-172.31.18.37-1671184955276:blk_1073741825_1001 src: /127.0.0.1:32988 dest: /127.0.0.1:50010
2022-12-16 11:03:37,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:32988, dest: /127.0.0.1:50010, bytes: 48, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1633842220_1, offset: 0, srvID: d2ef27b5-5432-4b03-a94f-ad62c09e634e, blockid: BP-2103221849-172.31.18.37-1671184955276:blk_1073741825_1001, duration(ns): 8001829
2022-12-16 11:03:37,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2103221849-172.31.18.37-1671184955276:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2022-12-16 11:04:34,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2103221849-172.31.18.37-1671184955276:blk_1073741826_1002 src: /127.0.0.1:47040 dest: /127.0.0.1:50010
2022-12-16 11:04:34,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:47040, dest: /127.0.0.1:50010, bytes: 25, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-186295993_1, offset: 0, srvID: d2ef27b5-5432-4b03-a94f-ad62c09e634e, blockid: BP-2103221849-172.31.18.37-1671184955276:blk_1073741826_1002, duration(ns): 3114392
2022-12-16 11:04:34,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2103221849-172.31.18.37-1671184955276:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2022-12-16 11:10:51,637 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2103221849-172.31.18.37-1671184955276:blk_1073741827_1003 src: /127.0.0.1:44094 dest: /127.0.0.1:50010
2022-12-16 11:10:51,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44094, dest: /127.0.0.1:50010, bytes: 20, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_65612099_1, offset: 0, srvID: d2ef27b5-5432-4b03-a94f-ad62c09e634e, blockid: BP-2103221849-172.31.18.37-1671184955276:blk_1073741827_1003, duration(ns): 3070097
2022-12-16 11:10:51,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2103221849-172.31.18.37-1671184955276:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2022-12-16 11:12:29,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2103221849-172.31.18.37-1671184955276:blk_1073741828_1004 src: /127.0.0.1:51008 dest: /127.0.0.1:50010
2022-12-16 11:12:29,103 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:51008, dest: /127.0.0.1:50010, bytes: 20, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1554765986_1, offset: 0, srvID: d2ef27b5-5432-4b03-a94f-ad62c09e634e, blockid: BP-2103221849-172.31.18.37-1671184955276:blk_1073741828_1004, duration(ns): 3969711
2022-12-16 11:12:29,103 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2103221849-172.31.18.37-1671184955276:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2022-12-16 11:14:16,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2103221849-172.31.18.37-1671184955276:blk_1073741829_1005 src: /127.0.0.1:53494 dest: /127.0.0.1:50010
2022-12-16 11:14:16,367 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:53494, dest: /127.0.0.1:50010, bytes: 20, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-373186678_1, offset: 0, srvID: d2ef27b5-5432-4b03-a94f-ad62c09e634e, blockid: BP-2103221849-172.31.18.37-1671184955276:blk_1073741829_1005, duration(ns): 3594158
2022-12-16 11:14:16,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2103221849-172.31.18.37-1671184955276:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2022-12-16 11:16:09,774 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2103221849-172.31.18.37-1671184955276:blk_1073741830_1006 src: /127.0.0.1:35946 dest: /127.0.0.1:50010
2022-12-16 11:16:09,778 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:35946, dest: /127.0.0.1:50010, bytes: 20, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-823966221_1, offset: 0, srvID: d2ef27b5-5432-4b03-a94f-ad62c09e634e, blockid: BP-2103221849-172.31.18.37-1671184955276:blk_1073741830_1006, duration(ns): 2920988
2022-12-16 11:16:09,778 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2103221849-172.31.18.37-1671184955276:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2022-12-16 11:21:49,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2103221849-172.31.18.37-1671184955276:blk_1073741831_1007 src: /127.0.0.1:55854 dest: /127.0.0.1:50010
2022-12-16 11:21:49,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55854, dest: /127.0.0.1:50010, bytes: 20, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-287201073_1, offset: 0, srvID: d2ef27b5-5432-4b03-a94f-ad62c09e634e, blockid: BP-2103221849-172.31.18.37-1671184955276:blk_1073741831_1007, duration(ns): 3475560
2022-12-16 11:21:49,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2103221849-172.31.18.37-1671184955276:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2022-12-16 11:33:54,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2103221849-172.31.18.37-1671184955276:blk_1073741832_1008 src: /127.0.0.1:50650 dest: /127.0.0.1:50010
2022-12-16 11:33:54,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50650, dest: /127.0.0.1:50010, bytes: 40, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1459332458_1, offset: 0, srvID: d2ef27b5-5432-4b03-a94f-ad62c09e634e, blockid: BP-2103221849-172.31.18.37-1671184955276:blk_1073741832_1008, duration(ns): 2951314
2022-12-16 11:33:54,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2103221849-172.31.18.37-1671184955276:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2022-12-16 11:35:59,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2103221849-172.31.18.37-1671184955276:blk_1073741833_1009 src: /127.0.0.1:50232 dest: /127.0.0.1:50010
2022-12-16 11:35:59,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50232, dest: /127.0.0.1:50010, bytes: 40, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_568147271_1, offset: 0, srvID: d2ef27b5-5432-4b03-a94f-ad62c09e634e, blockid: BP-2103221849-172.31.18.37-1671184955276:blk_1073741833_1009, duration(ns): 3801989
2022-12-16 11:35:59,232 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2103221849-172.31.18.37-1671184955276:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2022-12-16 11:36:40,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2103221849-172.31.18.37-1671184955276:blk_1073741834_1010 src: /127.0.0.1:58528 dest: /127.0.0.1:50010
2022-12-16 11:36:40,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:58528, dest: /127.0.0.1:50010, bytes: 40, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1802376983_1, offset: 0, srvID: d2ef27b5-5432-4b03-a94f-ad62c09e634e, blockid: BP-2103221849-172.31.18.37-1671184955276:blk_1073741834_1010, duration(ns): 2874275
2022-12-16 11:36:40,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2103221849-172.31.18.37-1671184955276:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2022-12-16 11:37:19,606 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2103221849-172.31.18.37-1671184955276:blk_1073741835_1011 src: /127.0.0.1:56378 dest: /127.0.0.1:50010
2022-12-16 11:37:19,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56378, dest: /127.0.0.1:50010, bytes: 40, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1270745784_1, offset: 0, srvID: d2ef27b5-5432-4b03-a94f-ad62c09e634e, blockid: BP-2103221849-172.31.18.37-1671184955276:blk_1073741835_1011, duration(ns): 3072276
2022-12-16 11:37:19,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2103221849-172.31.18.37-1671184955276:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2022-12-16 11:40:07,855 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2103221849-172.31.18.37-1671184955276:blk_1073741836_1012 src: /127.0.0.1:55708 dest: /127.0.0.1:50010
2022-12-16 11:40:07,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55708, dest: /127.0.0.1:50010, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1898449872_1, offset: 0, srvID: d2ef27b5-5432-4b03-a94f-ad62c09e634e, blockid: BP-2103221849-172.31.18.37-1671184955276:blk_1073741836_1012, duration(ns): 3488078
2022-12-16 11:40:07,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2103221849-172.31.18.37-1671184955276:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2022-12-16 11:50:33,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2103221849-172.31.18.37-1671184955276:blk_1073741837_1013 src: /127.0.0.1:43302 dest: /127.0.0.1:50010
2022-12-16 11:50:33,117 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:43302, dest: /127.0.0.1:50010, bytes: 290, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_647195576_1, offset: 0, srvID: d2ef27b5-5432-4b03-a94f-ad62c09e634e, blockid: BP-2103221849-172.31.18.37-1671184955276:blk_1073741837_1013, duration(ns): 2917402
2022-12-16 11:50:33,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2103221849-172.31.18.37-1671184955276:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2022-12-16 11:55:53,812 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2103221849-172.31.18.37-1671184955276:blk_1073741838_1014 src: /127.0.0.1:39256 dest: /127.0.0.1:50010
2022-12-16 11:55:53,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:39256, dest: /127.0.0.1:50010, bytes: 281, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1454429841_1, offset: 0, srvID: d2ef27b5-5432-4b03-a94f-ad62c09e634e, blockid: BP-2103221849-172.31.18.37-1671184955276:blk_1073741838_1014, duration(ns): 3301446
2022-12-16 11:55:53,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2103221849-172.31.18.37-1671184955276:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2022-12-16 11:57:53,884 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "MI104-08/172.31.18.37"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:827)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:791)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1564)
	at org.apache.hadoop.ipc.Client.call(Client.java:1506)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy16.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:166)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:516)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:646)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:851)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1865)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
2022-12-16 11:57:57,884 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-12-16 11:57:57,971 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2022-12-16 11:57:57,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at MI104-08/172.31.18.37
************************************************************/
2022-12-16 12:39:35,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = MI104-08/172.31.18.37
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.10.2
STARTUP_MSG:   classpath = /travail/te131323/hadoop/hadoop-2.10.2/etc/hadoop:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-json-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-digester-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hadoop-annotations-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-net-3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/junit-4.13.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/zookeeper-3.4.14.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/httpcore-4.4.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/gson-2.2.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsp-api-2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/httpclient-4.5.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/activation-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/stax2-api-4.2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/spotbugs-annotations-3.1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/hadoop-auth-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/json-smart-1.3.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jsch-0.1.55.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jettison-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-nfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/common/hadoop-common-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xercesImpl-2.12.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/netty-all-4.1.50.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/xml-apis-1.4.01.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jackson-databind-2.9.10.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-client-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/javax.inject-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/woodstox-core-5.3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/nimbus-jose-jwt-7.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/zookeeper-3.4.14.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-beanutils-1.9.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/audience-annotations-0.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/httpcore-4.4.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-framework-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/fst-2.50.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-client-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/httpclient-4.5.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/activation-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/stax2-api-4.2.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/curator-recipes-2.13.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/spotbugs-annotations-3.1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsr305-3.0.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/json-smart-1.3.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jsch-0.1.55.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/guice-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jettison-1.1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-router-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-client-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-registry-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/yarn/hadoop-yarn-api-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/commons-compress-1.21.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/junit-4.13.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/commons-io-2.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/reload4j-1.2.18.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/netty-3.10.6.Final.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.10.2-tests.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.10.2.jar:/travail/te131323/hadoop/hadoop-2.10.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.10.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r 965fd380006fa78b2315668fbc7eb432e1d8200f; compiled by 'ubuntu' on 2022-05-24T22:35Z
STARTUP_MSG:   java = 1.8.0_333
************************************************************/
2022-12-16 12:39:35,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2022-12-16 12:39:35,591 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/travail/te131323/datadir/
2022-12-16 12:39:35,637 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2022-12-16 12:39:35,685 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2022-12-16 12:39:35,685 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2022-12-16 12:39:35,840 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-12-16 12:39:35,847 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2022-12-16 12:39:35,848 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is MI104-08
2022-12-16 12:39:35,848 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-12-16 12:39:35,848 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2022-12-16 12:39:35,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2022-12-16 12:39:35,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2022-12-16 12:39:35,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2022-12-16 12:39:35,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2022-12-16 12:39:35,897 INFO org.mortbay.log: Logging to org.slf4j.impl.Reload4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2022-12-16 12:39:35,901 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-12-16 12:39:35,903 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2022-12-16 12:39:35,906 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2022-12-16 12:39:35,907 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2022-12-16 12:39:35,907 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-12-16 12:39:35,907 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-12-16 12:39:35,938 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 41147
2022-12-16 12:39:35,938 INFO org.mortbay.log: jetty-6.1.26
2022-12-16 12:39:36,029 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:41147
2022-12-16 12:39:36,101 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2022-12-16 12:39:36,103 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2022-12-16 12:39:36,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = te131323
2022-12-16 12:39:36,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2022-12-16 12:39:36,121 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2022-12-16 12:39:36,127 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2022-12-16 12:39:36,179 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2022-12-16 12:39:36,185 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2022-12-16 12:39:36,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2022-12-16 12:39:36,194 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2022-12-16 12:39:36,197 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2022-12-16 12:39:36,197 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2022-12-16 12:39:36,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2022-12-16 12:39:36,305 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2022-12-16 12:39:36,307 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /travail/te131323/datadir/in_use.lock acquired by nodename 3797826@MI104-08
2022-12-16 12:39:36,308 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /travail/te131323/datadir is not formatted for namespace 1544975200. Formatting...
2022-12-16 12:39:36,308 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-35e5194a-db5d-43d3-8c94-8ecbdfdedcad for directory /travail/te131323/datadir
2022-12-16 12:39:36,321 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-975021467-172.31.18.37-1671190764222
2022-12-16 12:39:36,322 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /travail/te131323/datadir/current/BP-975021467-172.31.18.37-1671190764222
2022-12-16 12:39:36,322 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /travail/te131323/datadir/current/BP-975021467-172.31.18.37-1671190764222 is not formatted for BP-975021467-172.31.18.37-1671190764222. Formatting ...
2022-12-16 12:39:36,322 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-975021467-172.31.18.37-1671190764222 directory /travail/te131323/datadir/current/BP-975021467-172.31.18.37-1671190764222/current
2022-12-16 12:39:36,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1544975200;bpid=BP-975021467-172.31.18.37-1671190764222;lv=-57;nsInfo=lv=-63;cid=CID-8e534a4d-82df-40c7-99b4-0c0f1687fe03;nsid=1544975200;c=1671190764222;bpid=BP-975021467-172.31.18.37-1671190764222;dnuuid=null
2022-12-16 12:39:36,324 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 27d3962c-0393-40bf-9457-90b2e97e7fe4
2022-12-16 12:39:36,331 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.lock-reporting-threshold-ms(300) assuming MILLISECONDS
2022-12-16 12:39:36,342 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-35e5194a-db5d-43d3-8c94-8ecbdfdedcad
2022-12-16 12:39:36,342 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /travail/te131323/datadir/current, StorageType: DISK
2022-12-16 12:39:36,344 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2022-12-16 12:39:36,347 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /travail/te131323/datadir/current
2022-12-16 12:39:36,350 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /travail/te131323/datadir/current
2022-12-16 12:39:36,351 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-975021467-172.31.18.37-1671190764222
2022-12-16 12:39:36,351 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-975021467-172.31.18.37-1671190764222 on volume /travail/te131323/datadir/current...
2022-12-16 12:39:36,368 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-975021467-172.31.18.37-1671190764222 on /travail/te131323/datadir/current: 16ms
2022-12-16 12:39:36,368 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-975021467-172.31.18.37-1671190764222: 16ms
2022-12-16 12:39:36,369 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-975021467-172.31.18.37-1671190764222 on volume /travail/te131323/datadir/current...
2022-12-16 12:39:36,369 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /travail/te131323/datadir/current/BP-975021467-172.31.18.37-1671190764222/current/replicas doesn't exist 
2022-12-16 12:39:36,370 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-975021467-172.31.18.37-1671190764222 on volume /travail/te131323/datadir/current: 1ms
2022-12-16 12:39:36,370 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-975021467-172.31.18.37-1671190764222: 2ms
2022-12-16 12:39:36,371 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-975021467-172.31.18.37-1671190764222 on volume /travail/te131323/datadir
2022-12-16 12:39:36,371 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/travail/te131323/datadir, DS-35e5194a-db5d-43d3-8c94-8ecbdfdedcad): finished scanning block pool BP-975021467-172.31.18.37-1671190764222
2022-12-16 12:39:36,374 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 16/12/22 13:36 with interval of 21600000ms
2022-12-16 12:39:36,375 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-975021467-172.31.18.37-1671190764222 (Datanode Uuid 27d3962c-0393-40bf-9457-90b2e97e7fe4) service to localhost/127.0.0.1:9000 beginning handshake with NN
2022-12-16 12:39:36,385 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/travail/te131323/datadir, DS-35e5194a-db5d-43d3-8c94-8ecbdfdedcad): no suitable block pools found to scan.  Waiting 1814399986 ms.
2022-12-16 12:39:36,411 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-975021467-172.31.18.37-1671190764222 (Datanode Uuid 27d3962c-0393-40bf-9457-90b2e97e7fe4) service to localhost/127.0.0.1:9000 successfully registered with NN
2022-12-16 12:39:36,411 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2022-12-16 12:39:36,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xcdf2f28d7f5a7234,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 28 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2022-12-16 12:39:36,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-975021467-172.31.18.37-1671190764222
2022-12-16 12:40:25,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-975021467-172.31.18.37-1671190764222:blk_1073741825_1001 src: /127.0.0.1:50214 dest: /127.0.0.1:50010
2022-12-16 12:40:25,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50214, dest: /127.0.0.1:50010, bytes: 48, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1763241698_1, offset: 0, srvID: 27d3962c-0393-40bf-9457-90b2e97e7fe4, blockid: BP-975021467-172.31.18.37-1671190764222:blk_1073741825_1001, duration(ns): 7095552
2022-12-16 12:40:25,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-975021467-172.31.18.37-1671190764222:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2022-12-16 12:40:32,211 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-975021467-172.31.18.37-1671190764222:blk_1073741826_1002 src: /127.0.0.1:33604 dest: /127.0.0.1:50010
2022-12-16 12:40:32,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:33604, dest: /127.0.0.1:50010, bytes: 281, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-51905801_1, offset: 0, srvID: 27d3962c-0393-40bf-9457-90b2e97e7fe4, blockid: BP-975021467-172.31.18.37-1671190764222:blk_1073741826_1002, duration(ns): 3155032
2022-12-16 12:40:32,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-975021467-172.31.18.37-1671190764222:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2022-12-16 12:44:23,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-975021467-172.31.18.37-1671190764222:blk_1073741827_1003 src: /127.0.0.1:57434 dest: /127.0.0.1:50010
2022-12-16 12:44:23,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:57434, dest: /127.0.0.1:50010, bytes: 75379926, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-76336476_1, offset: 0, srvID: 27d3962c-0393-40bf-9457-90b2e97e7fe4, blockid: BP-975021467-172.31.18.37-1671190764222:blk_1073741827_1003, duration(ns): 77961598
2022-12-16 12:44:23,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-975021467-172.31.18.37-1671190764222:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2022-12-16 12:44:36,774 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /travail/te131323/datadir/current
2022-12-16 12:44:36,774 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: BlockSender.sendChunks() exception: 
java.io.IOException: Connexion ré-initialisée par le correspondant
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:605)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:223)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:621)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:805)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:752)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:609)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:145)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:100)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:290)
	at java.lang.Thread.run(Thread.java:750)
2022-12-16 12:45:49,278 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/travail/te131323/datadir, DS-35e5194a-db5d-43d3-8c94-8ecbdfdedcad): no suitable block pools found to scan.  Waiting 1814027093 ms.
2022-12-16 13:03:45,508 INFO org.apache.hadoop.http.HttpServer2: Process Thread Dump: jsp requested
62 active threads
Thread 113 (nioEventLoopGroup-3-19):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    io.netty.channel.DefaultChannelPromise.<init>(DefaultChannelPromise.java:53)
    io.netty.channel.AbstractChannelHandlerContext.newPromise(AbstractChannelHandlerContext.java:819)
    io.netty.channel.AbstractChannelHandlerContext.writeAndFlush(AbstractChannelHandlerContext.java:808)
    io.netty.channel.DefaultChannelPipeline.writeAndFlush(DefaultChannelPipeline.java:1025)
    io.netty.channel.AbstractChannel.writeAndFlush(AbstractChannel.java:294)
    org.apache.hadoop.hdfs.server.datanode.web.SimpleHttpProxyHandler$Forwarder.channelRead(SimpleHttpProxyHandler.java:78)
    io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
    io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
    io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
    io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
    io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
    io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
    io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
    io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
    io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)
    io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
    io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
    io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
    io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
    io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
Thread 112 (nioEventLoopGroup-3-18):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
    io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:803)
    io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
    io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
    io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
    io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:750)
Thread 111 (nioEventLoopGroup-3-17):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
    io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:803)
    io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
    io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
    io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
    io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:750)
Thread 110 (nioEventLoopGroup-3-16):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
    io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:803)
    io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
    io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
    io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
    io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:750)
Thread 109 (nioEventLoopGroup-3-15):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
    io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:803)
    io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
    io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
    io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
    io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:750)
Thread 108 (nioEventLoopGroup-3-14):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
    io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:803)
    io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
    io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
    io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
    io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:750)
Thread 105 (nioEventLoopGroup-3-13):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
    io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:803)
    io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
    io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
    io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
    io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:750)
Thread 104 (nioEventLoopGroup-3-12):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
    io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:803)
    io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
    io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
    io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
    io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:750)
Thread 103 (nioEventLoopGroup-3-11):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
    io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:803)
    io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
    io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
    io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
    io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:750)
Thread 102 (nioEventLoopGroup-3-10):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
    io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:803)
    io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
    io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
    io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
    io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:750)
Thread 97 (1277459482@qtp-187457031-3):
  State: RUNNABLE
  Blocked count: 25
  Waited count: 36
  Stack:
    sun.management.ThreadImpl.getThreadInfo1(Native Method)
    sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:178)
    sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:139)
    org.apache.hadoop.util.ReflectionUtils.printThreadInfo(ReflectionUtils.java:169)
    org.apache.hadoop.util.ReflectionUtils.logThreadInfo(ReflectionUtils.java:253)
    org.apache.hadoop.http.HttpServer2$StackServlet.doGet(HttpServer2.java:1293)
    javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
    javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
    org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
    org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1221)
    org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:110)
    org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
    org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1429)
    org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
    org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
    org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
    org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
    org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
    org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)
    org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
Thread 95 (nioEventLoopGroup-3-9):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
    io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:803)
    io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
    io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
    io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
    io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:750)
Thread 94 (nioEventLoopGroup-3-8):
  State: RUNNABLE
  Blocked count: 2
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
    io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:803)
    io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
    io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
    io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
    io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:750)
Thread 93 (nioEventLoopGroup-3-7):
  State: RUNNABLE
  Blocked count: 3
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
    io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:803)
    io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
    io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
    io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
    io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:750)
Thread 92 (nioEventLoopGroup-3-6):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
    io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:803)
    io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
    io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
    io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
    io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:750)
Thread 91 (nioEventLoopGroup-3-5):
  State: RUNNABLE
  Blocked count: 1
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
    io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:803)
    io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
    io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
    io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
    io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:750)
Thread 90 (nioEventLoopGroup-3-4):
  State: RUNNABLE
  Blocked count: 2
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
    io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:803)
    io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
    io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
    io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
    io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:750)
Thread 89 (nioEventLoopGroup-3-3):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
    io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:803)
    io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
    io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
    io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
    io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:750)
Thread 88 (nioEventLoopGroup-3-2):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
    io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:803)
    io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
    io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
    io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
    io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:750)
Thread 87 (nioEventLoopGroup-3-1):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
    io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:803)
    io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
    io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
    io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
    io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:750)
Thread 82 (Readahead Thread #3):
  State: WAITING
  Blocked count: 0
  Waited count: 27
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@60e2a6d
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:750)
Thread 81 (Readahead Thread #2):
  State: WAITING
  Blocked count: 0
  Waited count: 27
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@60e2a6d
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:750)
Thread 80 (Readahead Thread #1):
  State: WAITING
  Blocked count: 0
  Waited count: 27
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@60e2a6d
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:750)
Thread 79 (Readahead Thread #0):
  State: WAITING
  Blocked count: 0
  Waited count: 29
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@60e2a6d
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:750)
Thread 69 (java.util.concurrent.ThreadPoolExecutor$Worker@545d9da7[State = -1, empty queue]):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:750)
Thread 62 (refreshUsed-/travail/te131323/datadir/current/BP-975021467-172.31.18.37-1671190764222):
  State: TIMED_WAITING
  Blocked count: 2
  Waited count: 5
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:205)
    java.lang.Thread.run(Thread.java:750)
Thread 59 (pool-4-thread-1):
  State: WAITING
  Blocked count: 0
  Waited count: 2
  Waiting on java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@6c933ddf
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1081)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:750)
Thread 57 (VolumeScannerThread(/travail/te131323/datadir)):
  State: TIMED_WAITING
  Blocked count: 2
  Waited count: 148
  Stack:
    java.lang.Object.wait(Native Method)
    org.apache.hadoop.hdfs.server.datanode.VolumeScanner.run(VolumeScanner.java:627)
Thread 56 (IPC Parameter Sending Thread #0):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 490
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
    java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
    java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:750)
Thread 55 (IPC Client (1067084817) connection to localhost/127.0.0.1:9000 from te131323):
  State: TIMED_WAITING
  Blocked count: 489
  Waited count: 490
  Stack:
    java.lang.Object.wait(Native Method)
    org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1053)
    org.apache.hadoop.ipc.Client$Connection.run(Client.java:1097)
Thread 54 (IPC Server handler 9 on default port 50020):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1809
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:294)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2820)
Thread 53 (IPC Server handler 8 on default port 50020):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1812
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:294)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2820)
Thread 52 (IPC Server handler 7 on default port 50020):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1827
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:294)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2820)
Thread 51 (IPC Server handler 6 on default port 50020):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1867
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:294)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2820)
Thread 50 (IPC Server handler 5 on default port 50020):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1874
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:294)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2820)
Thread 49 (IPC Server handler 4 on default port 50020):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1840
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:294)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2820)
Thread 48 (IPC Server handler 3 on default port 50020):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1774
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:294)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2820)
Thread 47 (IPC Server handler 2 on default port 50020):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 2000
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:294)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2820)
Thread 46 (IPC Server handler 1 on default port 50020):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1835
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:294)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2820)
Thread 45 (IPC Server handler 0 on default port 50020):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1954
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
    org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:294)
    org.apache.hadoop.ipc.Server$Handler.run(Server.java:2820)
Thread 38 (IPC Server listener on 50020):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    org.apache.hadoop.ipc.Server$Listener.run(Server.java:1314)
Thread 41 (IPC Server Responder):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1491)
    org.apache.hadoop.ipc.Server$Responder.run(Server.java:1474)
Thread 27 (org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@75d2da2d):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
    sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:424)
    sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:252)
    sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:100)
    org.apache.hadoop.hdfs.net.TcpPeerServer.accept(TcpPeerServer.java:85)
    org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:145)
    java.lang.Thread.run(Thread.java:750)
Thread 44 (pool-9-thread-1):
  State: TIMED_WAITING
  Blocked count: 5
  Waited count: 3
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:750)
Thread 43 (AsyncAppender-Dispatcher-Thread-20):
  State: WAITING
  Blocked count: 243
  Waited count: 244
  Waiting on java.util.ArrayList@48c1f8ed
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:502)
    org.apache.log4j.AsyncAppender$Dispatcher.run(AsyncAppender.java:539)
    java.lang.Thread.run(Thread.java:750)
Thread 42 (BP-975021467-172.31.18.37-1671190764222 heartbeating to localhost/127.0.0.1:9000):
  State: TIMED_WAITING
  Blocked count: 496
  Waited count: 1469
  Stack:
    java.lang.Object.wait(Native Method)
    org.apache.hadoop.hdfs.server.datanode.IncrementalBlockReportManager.waitTillNextIBR(IncrementalBlockReportManager.java:158)
    org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:715)
    org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:851)
    java.lang.Thread.run(Thread.java:750)
Thread 40 (IPC Server idle connection scanner for port 50020):
  State: TIMED_WAITING
  Blocked count: 1
  Waited count: 146
  Stack:
    java.lang.Object.wait(Native Method)
    java.util.TimerThread.mainLoop(Timer.java:552)
    java.util.TimerThread.run(Timer.java:505)
Thread 39 (Socket Reader #1 for port 50020):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1252)
    org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1231)
Thread 37 (org.apache.hadoop.util.JvmPauseMonitor$Monitor@33617539):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 2899
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
    java.lang.Thread.run(Thread.java:750)
Thread 36 (nioEventLoopGroup-2-1):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
    io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:803)
    io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
    io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
    io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
    io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    java.lang.Thread.run(Thread.java:750)
Thread 35 (Timer-2):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 49
  Stack:
    java.lang.Object.wait(Native Method)
    java.util.TimerThread.mainLoop(Timer.java:552)
    java.util.TimerThread.run(Timer.java:505)
Thread 34 (Timer-1):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 49
  Stack:
    java.lang.Object.wait(Native Method)
    java.util.TimerThread.mainLoop(Timer.java:552)
    java.util.TimerThread.run(Timer.java:505)
Thread 33 (Timer-0):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 49
  Stack:
    java.lang.Object.wait(Native Method)
    java.util.TimerThread.mainLoop(Timer.java:552)
    java.util.TimerThread.run(Timer.java:505)
Thread 32 (1216198248@qtp-187457031-1 - Acceptor0 HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:41147):
  State: RUNNABLE
  Blocked count: 2
  Waited count: 1
  Stack:
    sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
    sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    org.mortbay.io.nio.SelectorManager$SelectSet.doSelect(SelectorManager.java:498)
    org.mortbay.io.nio.SelectorManager.doSelect(SelectorManager.java:192)
    org.mortbay.jetty.nio.SelectChannelConnector.accept(SelectChannelConnector.java:124)
    org.mortbay.jetty.AbstractConnector$Acceptor.run(AbstractConnector.java:708)
    org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)
Thread 30 (pool-6-thread-1):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 1
  Stack:
    sun.misc.Unsafe.park(Native Method)
    java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
    java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
    java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    java.lang.Thread.run(Thread.java:750)
Thread 28 (datanode DomainSocketWatcher):
  State: RUNNABLE
  Blocked count: 1
  Waited count: 0
  Stack:
    org.apache.hadoop.net.unix.DomainSocketWatcher.doPoll0(Native Method)
    org.apache.hadoop.net.unix.DomainSocketWatcher.access$900(DomainSocketWatcher.java:52)
    org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:503)
    java.lang.Thread.run(Thread.java:750)
Thread 25 (Timer for 'DataNode' metrics system):
  State: TIMED_WAITING
  Blocked count: 1
  Waited count: 146
  Stack:
    java.lang.Object.wait(Native Method)
    java.util.TimerThread.mainLoop(Timer.java:552)
    java.util.TimerThread.run(Timer.java:505)
Thread 22 (org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner):
  State: WAITING
  Blocked count: 0
  Waited count: 1
  Waiting on java.lang.ref.ReferenceQueue$Lock@5bd73d1a
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:150)
    java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:171)
    org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner.run(FileSystem.java:3712)
    java.lang.Thread.run(Thread.java:750)
Thread 4 (Signal Dispatcher):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
Thread 3 (Finalizer):
  State: WAITING
  Blocked count: 8
  Waited count: 6
  Waiting on java.lang.ref.ReferenceQueue$Lock@2555fff0
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:150)
    java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:171)
    java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:216)
Thread 2 (Reference Handler):
  State: WAITING
  Blocked count: 4
  Waited count: 4
  Waiting on java.lang.ref.Reference$Lock@70d2e40b
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:502)
    java.lang.ref.Reference.tryHandlePending(Reference.java:191)
    java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)
Thread 1 (Listener at 0.0.0.0/50020):
  State: WAITING
  Blocked count: 5
  Waited count: 3
  Waiting on java.lang.Thread@7b8feaf6
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Thread.join(Thread.java:1257)
    java.lang.Thread.join(Thread.java:1331)
    org.apache.hadoop.hdfs.server.datanode.BPServiceActor.join(BPServiceActor.java:581)
    org.apache.hadoop.hdfs.server.datanode.BPOfferService.join(BPOfferService.java:355)
    org.apache.hadoop.hdfs.server.datanode.BlockPoolManager.joinAll(BlockPoolManager.java:143)
    org.apache.hadoop.hdfs.server.datanode.DataNode.join(DataNode.java:2672)
    org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2808)
    org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2830)

2022-12-16 13:36:57,378 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-975021467-172.31.18.37-1671190764222 Total blocks: 3, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2022-12-16 14:41:30,619 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xcdf2f28d7f5a7235,  containing 1 storage report(s), of which we sent 1. The reports had 3 total blocks and used 1 RPC(s). This took 1 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2022-12-16 14:41:30,619 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-975021467-172.31.18.37-1671190764222
2022-12-16 15:02:16,479 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-975021467-172.31.18.37-1671190764222:blk_1073741828_1004 src: /127.0.0.1:45808 dest: /127.0.0.1:50010
2022-12-16 15:02:16,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:45808, dest: /127.0.0.1:50010, bytes: 8762071, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_144108398_1, offset: 0, srvID: 27d3962c-0393-40bf-9457-90b2e97e7fe4, blockid: BP-975021467-172.31.18.37-1671190764222:blk_1073741828_1004, duration(ns): 13152975
2022-12-16 15:02:16,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-975021467-172.31.18.37-1671190764222:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2022-12-16 15:18:38,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-975021467-172.31.18.37-1671190764222:blk_1073741829_1005 src: /127.0.0.1:36708 dest: /127.0.0.1:50010
2022-12-16 15:18:38,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:36708, dest: /127.0.0.1:50010, bytes: 16805896, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1618782266_1, offset: 0, srvID: 27d3962c-0393-40bf-9457-90b2e97e7fe4, blockid: BP-975021467-172.31.18.37-1671190764222:blk_1073741829_1005, duration(ns): 395458133
2022-12-16 15:18:38,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-975021467-172.31.18.37-1671190764222:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2022-12-16 19:36:57,375 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-975021467-172.31.18.37-1671190764222 Total blocks: 5, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2022-12-16 20:41:28,213 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xcdf2f28d7f5a7236,  containing 1 storage report(s), of which we sent 1. The reports had 5 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2022-12-16 20:41:28,213 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-975021467-172.31.18.37-1671190764222
2022-12-16 23:16:41,298 WARN org.apache.hadoop.fs.CachingGetSpaceUsed: Could not get disk usage information for path /travail/te131323/datadir/current/BP-975021467-172.31.18.37-1671190764222
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU$DUShell.parseExecResult(DU.java:79)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:984)
	at org.apache.hadoop.util.Shell.run(Shell.java:884)
	at org.apache.hadoop.fs.DU$DUShell.startRefresh(DU.java:62)
	at org.apache.hadoop.fs.DU.refresh(DU.java:53)
	at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:209)
	at java.lang.Thread.run(Thread.java:750)
2022-12-16 23:26:50,457 WARN org.apache.hadoop.fs.CachingGetSpaceUsed: Could not get disk usage information for path /travail/te131323/datadir/current/BP-975021467-172.31.18.37-1671190764222
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU$DUShell.parseExecResult(DU.java:79)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:984)
	at org.apache.hadoop.util.Shell.run(Shell.java:884)
	at org.apache.hadoop.fs.DU$DUShell.startRefresh(DU.java:62)
	at org.apache.hadoop.fs.DU.refresh(DU.java:53)
	at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:209)
	at java.lang.Thread.run(Thread.java:750)
2022-12-16 23:37:36,635 WARN org.apache.hadoop.fs.CachingGetSpaceUsed: Could not get disk usage information for path /travail/te131323/datadir/current/BP-975021467-172.31.18.37-1671190764222
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU$DUShell.parseExecResult(DU.java:79)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:984)
	at org.apache.hadoop.util.Shell.run(Shell.java:884)
	at org.apache.hadoop.fs.DU$DUShell.startRefresh(DU.java:62)
	at org.apache.hadoop.fs.DU.refresh(DU.java:53)
	at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:209)
	at java.lang.Thread.run(Thread.java:750)
2022-12-16 23:47:46,665 WARN org.apache.hadoop.fs.CachingGetSpaceUsed: Could not get disk usage information for path /travail/te131323/datadir/current/BP-975021467-172.31.18.37-1671190764222
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU$DUShell.parseExecResult(DU.java:79)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:984)
	at org.apache.hadoop.util.Shell.run(Shell.java:884)
	at org.apache.hadoop.fs.DU$DUShell.startRefresh(DU.java:62)
	at org.apache.hadoop.fs.DU.refresh(DU.java:53)
	at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:209)
	at java.lang.Thread.run(Thread.java:750)
2022-12-16 23:58:01,482 WARN org.apache.hadoop.fs.CachingGetSpaceUsed: Could not get disk usage information for path /travail/te131323/datadir/current/BP-975021467-172.31.18.37-1671190764222
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU$DUShell.parseExecResult(DU.java:79)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:984)
	at org.apache.hadoop.util.Shell.run(Shell.java:884)
	at org.apache.hadoop.fs.DU$DUShell.startRefresh(DU.java:62)
	at org.apache.hadoop.fs.DU.refresh(DU.java:53)
	at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:209)
	at java.lang.Thread.run(Thread.java:750)
2022-12-17 00:08:20,833 WARN org.apache.hadoop.fs.CachingGetSpaceUsed: Could not get disk usage information for path /travail/te131323/datadir/current/BP-975021467-172.31.18.37-1671190764222
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU$DUShell.parseExecResult(DU.java:79)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:984)
	at org.apache.hadoop.util.Shell.run(Shell.java:884)
	at org.apache.hadoop.fs.DU$DUShell.startRefresh(DU.java:62)
	at org.apache.hadoop.fs.DU.refresh(DU.java:53)
	at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:209)
	at java.lang.Thread.run(Thread.java:750)
2022-12-17 00:17:45,639 WARN org.apache.hadoop.fs.CachingGetSpaceUsed: Could not get disk usage information for path /travail/te131323/datadir/current/BP-975021467-172.31.18.37-1671190764222
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU$DUShell.parseExecResult(DU.java:79)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:984)
	at org.apache.hadoop.util.Shell.run(Shell.java:884)
	at org.apache.hadoop.fs.DU$DUShell.startRefresh(DU.java:62)
	at org.apache.hadoop.fs.DU.refresh(DU.java:53)
	at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:209)
	at java.lang.Thread.run(Thread.java:750)
2022-12-17 00:28:16,222 WARN org.apache.hadoop.fs.CachingGetSpaceUsed: Could not get disk usage information for path /travail/te131323/datadir/current/BP-975021467-172.31.18.37-1671190764222
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU$DUShell.parseExecResult(DU.java:79)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:984)
	at org.apache.hadoop.util.Shell.run(Shell.java:884)
	at org.apache.hadoop.fs.DU$DUShell.startRefresh(DU.java:62)
	at org.apache.hadoop.fs.DU.refresh(DU.java:53)
	at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:209)
	at java.lang.Thread.run(Thread.java:750)
2022-12-17 00:38:33,508 WARN org.apache.hadoop.fs.CachingGetSpaceUsed: Could not get disk usage information for path /travail/te131323/datadir/current/BP-975021467-172.31.18.37-1671190764222
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU$DUShell.parseExecResult(DU.java:79)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:984)
	at org.apache.hadoop.util.Shell.run(Shell.java:884)
	at org.apache.hadoop.fs.DU$DUShell.startRefresh(DU.java:62)
	at org.apache.hadoop.fs.DU.refresh(DU.java:53)
	at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:209)
	at java.lang.Thread.run(Thread.java:750)
2022-12-17 00:49:10,702 WARN org.apache.hadoop.fs.CachingGetSpaceUsed: Could not get disk usage information for path /travail/te131323/datadir/current/BP-975021467-172.31.18.37-1671190764222
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU$DUShell.parseExecResult(DU.java:79)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:984)
	at org.apache.hadoop.util.Shell.run(Shell.java:884)
	at org.apache.hadoop.fs.DU$DUShell.startRefresh(DU.java:62)
	at org.apache.hadoop.fs.DU.refresh(DU.java:53)
	at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:209)
	at java.lang.Thread.run(Thread.java:750)
2022-12-17 00:59:08,529 WARN org.apache.hadoop.fs.CachingGetSpaceUsed: Could not get disk usage information for path /travail/te131323/datadir/current/BP-975021467-172.31.18.37-1671190764222
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU$DUShell.parseExecResult(DU.java:79)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:984)
	at org.apache.hadoop.util.Shell.run(Shell.java:884)
	at org.apache.hadoop.fs.DU$DUShell.startRefresh(DU.java:62)
	at org.apache.hadoop.fs.DU.refresh(DU.java:53)
	at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:209)
	at java.lang.Thread.run(Thread.java:750)
2022-12-17 01:10:03,066 WARN org.apache.hadoop.fs.CachingGetSpaceUsed: Could not get disk usage information for path /travail/te131323/datadir/current/BP-975021467-172.31.18.37-1671190764222
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU$DUShell.parseExecResult(DU.java:79)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:984)
	at org.apache.hadoop.util.Shell.run(Shell.java:884)
	at org.apache.hadoop.fs.DU$DUShell.startRefresh(DU.java:62)
	at org.apache.hadoop.fs.DU.refresh(DU.java:53)
	at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:209)
	at java.lang.Thread.run(Thread.java:750)
2022-12-17 01:19:35,950 WARN org.apache.hadoop.fs.CachingGetSpaceUsed: Could not get disk usage information for path /travail/te131323/datadir/current/BP-975021467-172.31.18.37-1671190764222
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU$DUShell.parseExecResult(DU.java:79)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:984)
	at org.apache.hadoop.util.Shell.run(Shell.java:884)
	at org.apache.hadoop.fs.DU$DUShell.startRefresh(DU.java:62)
	at org.apache.hadoop.fs.DU.refresh(DU.java:53)
	at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:209)
	at java.lang.Thread.run(Thread.java:750)
2022-12-17 01:30:33,698 WARN org.apache.hadoop.fs.CachingGetSpaceUsed: Could not get disk usage information for path /travail/te131323/datadir/current/BP-975021467-172.31.18.37-1671190764222
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU$DUShell.parseExecResult(DU.java:79)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:984)
	at org.apache.hadoop.util.Shell.run(Shell.java:884)
	at org.apache.hadoop.fs.DU$DUShell.startRefresh(DU.java:62)
	at org.apache.hadoop.fs.DU.refresh(DU.java:53)
	at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:209)
	at java.lang.Thread.run(Thread.java:750)
2022-12-17 01:36:57,374 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /travail/te131323/datadir/current
2022-12-17 01:36:57,374 WARN org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Exception occured while compiling report: 
java.nio.file.NoSuchFileException: /travail/te131323/datadir/current/BP-975021467-172.31.18.37-1671190764222/current/finalized
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:427)
	at java.nio.file.Files.newDirectoryStream(Files.java:457)
	at org.apache.hadoop.io.IOUtils.listDirectory(IOUtils.java:386)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.listDirectory(FileIoProvider.java:782)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.compileReport(DirectoryScanner.java:873)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.call(DirectoryScanner.java:844)
	at org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.call(DirectoryScanner.java:807)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2022-12-17 01:36:57,375 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /travail/te131323/datadir/current
2022-12-17 01:36:57,375 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-975021467-172.31.18.37-1671190764222 Total blocks: 0, missing metadata files:5, missing block files:5, missing blocks in memory:0, mismatched blocks:0
2022-12-17 01:36:57,375 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741825 from memory with missing block file on the disk
2022-12-17 01:36:59,375 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741826 from memory with missing block file on the disk
2022-12-17 01:36:59,375 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741827 from memory with missing block file on the disk
2022-12-17 01:36:59,375 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741828 from memory with missing block file on the disk
2022-12-17 01:36:59,375 WARN org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Removed block 1073741829 from memory with missing block file on the disk
2022-12-17 02:41:28,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xcdf2f28d7f5a7237,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2022-12-17 02:41:28,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-975021467-172.31.18.37-1671190764222
2022-12-17 07:36:57,374 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-975021467-172.31.18.37-1671190764222 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2022-12-17 08:41:29,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xcdf2f28d7f5a7238,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2022-12-17 08:41:29,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-975021467-172.31.18.37-1671190764222
2022-12-17 13:36:57,374 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-975021467-172.31.18.37-1671190764222 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2022-12-17 14:41:30,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xcdf2f28d7f5a7239,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2022-12-17 14:41:30,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-975021467-172.31.18.37-1671190764222
2022-12-17 17:32:18,949 WARN org.apache.hadoop.fs.CachingGetSpaceUsed: Could not get disk usage information for path /travail/te131323/datadir/current/BP-975021467-172.31.18.37-1671190764222
java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DU$DUShell.parseExecResult(DU.java:79)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:984)
	at org.apache.hadoop.util.Shell.run(Shell.java:884)
	at org.apache.hadoop.fs.DU$DUShell.startRefresh(DU.java:62)
	at org.apache.hadoop.fs.DU.refresh(DU.java:53)
	at org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread.run(CachingGetSpaceUsed.java:209)
	at java.lang.Thread.run(Thread.java:750)
